device: cuda
duration: 1202.295156955719
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  num_workers: 4
  save_freq: 30
loss:
  args: {}
  class: CrossEntropyLoss
metrics:
  svhn_top1_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 1
    class: Accuracy
  svhn_top5_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 5
    class: Accuracy
model:
  args:
    depth: 28
    num_classes: 10
    width: 2
  class: WideResNet
optimizer:
  args:
    lr: 0.0003
  class: Adam
train_dataset:
  args:
    num_labeled: 1000
    root: ./data/
    train_val_split: 0.9
  class: FineTuningTrainSVHN
train_history:
  loss:
    total:
    - 2.2869876623153687
    - 2.2278730273246765
    - 2.1753698587417603
    - 2.1289877593517303
    - 2.07920803129673
    - 2.0444935262203217
    - 2.0199592858552933
    - 1.9780653715133667
    - 1.9570630639791489
    - 1.9322350919246674
    - 1.8963082283735275
    - 1.8638217002153397
    - 1.830118179321289
    - 1.8055514246225357
    - 1.7720392942428589
    - 1.7538290917873383
    - 1.7193721532821655
    - 1.6849534660577774
    - 1.6414975821971893
    - 1.6142212748527527
    - 1.5825842767953873
    - 1.573126181960106
    - 1.5188319981098175
    - 1.4960687458515167
    - 1.4654650539159775
    - 1.4357299208641052
    - 1.406155288219452
    - 1.3943610489368439
    - 1.384931355714798
    - 1.3540062010288239
    - 1.345068410038948
    - 1.315846011042595
    - 1.2946030050516129
    - 1.2599221915006638
    - 1.2101876437664032
    - 1.204621598124504
    - 1.1798368245363235
    - 1.1487848460674286
    - 1.1223409324884415
    - 1.1102380454540253
    - 1.0921752452850342
    - 1.0652433931827545
    - 1.0376059710979462
    - 1.003058522939682
    - 0.9857919439673424
    - 0.9737969860434532
    - 0.9566141217947006
    - 0.93914595246315
    - 0.9306517839431763
    - 0.8978678658604622
    - 0.872967541217804
    - 0.865095391869545
    - 0.8557579815387726
    - 0.827022984623909
    - 0.8233458548784256
    - 0.8054322227835655
    - 0.7770058661699295
    - 0.7738665491342545
    - 0.743022233247757
    - 0.7236386463046074
    - 0.7161785885691643
    - 0.7119530960917473
    - 0.6991687193512917
    - 0.6716346740722656
    - 0.6551586613059044
    - 0.6282595694065094
    - 0.6293003633618355
    - 0.5990259945392609
    - 0.5820270553231239
    - 0.5648917034268379
    - 0.5541260316967964
    - 0.5465208031237125
    - 0.5423588268458843
    - 0.5397552140057087
    - 0.5284317582845688
    - 0.5014717653393745
    - 0.4943154379725456
    - 0.4680001698434353
    - 0.47435059770941734
    - 0.4514898359775543
    - 0.43405357375741005
    - 0.4202624708414078
    - 0.4282400384545326
    - 0.42224155738949776
    - 0.4076257273554802
    - 0.39286917075514793
    - 0.3928751163184643
    - 0.3686729408800602
    - 0.36199812963604927
    - 0.3535327725112438
    - 0.35129162669181824
    - 0.3502379059791565
    - 0.33917953073978424
    - 0.3322565034031868
    - 0.3270351327955723
    - 0.3250465765595436
    - 0.30787522345781326
    - 0.30900900810956955
    - 0.2871642895042896
    - 0.2920036297291517
  metrics:
    svhn_top1_accuracy:
    - 0.14806189946830273
    - 0.21536959148943424
    - 0.2660006023943424
    - 0.29409555345773697
    - 0.3057391829788685
    - 0.31986177898943424
    - 0.3170072101056576
    - 0.31768329441547394
    - 0.3267728351056576
    - 0.3326322101056576
    - 0.3602764420211315
    - 0.37334735691547394
    - 0.38934795558452606
    - 0.40249399095773697
    - 0.4063251204788685
    - 0.41293569654226303
    - 0.42788461595773697
    - 0.45537860691547394
    - 0.4698016829788685
    - 0.46897535771131516
    - 0.4960186332464218
    - 0.49481670558452606
    - 0.522611178457737
    - 0.5401141792535782
    - 0.5504807680845261
    - 0.5549879819154739
    - 0.5557391792535782
    - 0.5887920707464218
    - 0.5849609375
    - 0.5866887047886848
    - 0.5733173042535782
    - 0.6198918297886848
    - 0.6183894202113152
    - 0.6343149021267891
    - 0.6678936332464218
    - 0.6479867771267891
    - 0.6729266792535782
    - 0.6714994013309479
    - 0.7025991603732109
    - 0.6953876167535782
    - 0.7146183922886848
    - 0.7192758396267891
    - 0.7329477146267891
    - 0.7479717582464218
    - 0.7393329292535782
    - 0.7563100978732109
    - 0.775390625
    - 0.7578876167535782
    - 0.7665264457464218
    - 0.7853816077113152
    - 0.7897385805845261
    - 0.8001051694154739
    - 0.794771634042263
    - 0.8052884638309479
    - 0.7971754819154739
    - 0.807466946542263
    - 0.814453125
    - 0.8131760805845261
    - 0.827974759042263
    - 0.8210637047886848
    - 0.8364633396267891
    - 0.8396183922886848
    - 0.8496844917535782
    - 0.853365384042263
    - 0.8588491603732109
    - 0.8718449547886848
    - 0.8747746422886848
    - 0.8792067319154739
    - 0.8952073305845261
    - 0.899564303457737
    - 0.9022686332464218
    - 0.8961838930845261
    - 0.8942307680845261
    - 0.8987379819154739
    - 0.8964092582464218
    - 0.9108323305845261
    - 0.9166917055845261
    - 0.9352463930845261
    - 0.9147385805845261
    - 0.9271334111690521
    - 0.942232571542263
    - 0.9344951957464218
    - 0.9351712763309479
    - 0.9364483207464218
    - 0.933743990957737
    - 0.9524489194154739
    - 0.9492938667535782
    - 0.9544020444154739
    - 0.9512469917535782
    - 0.9586087763309479
    - 0.9590594917535782
    - 0.9629657417535782
    - 0.9619891792535782
    - 0.9670973569154739
    - 0.9682992771267891
    - 0.9653695896267891
    - 0.9751352146267891
    - 0.9692758396267891
    - 0.9809945896267891
    - 0.9773137047886848
    svhn_top5_accuracy:
    - 0.5756460353732109
    - 0.6652644202113152
    - 0.7074819728732109
    - 0.7309194728732109
    - 0.7405348569154739
    - 0.7520282417535782
    - 0.7651742771267891
    - 0.783203125
    - 0.802584134042263
    - 0.8150540888309479
    - 0.836763821542263
    - 0.835787259042263
    - 0.8448016792535782
    - 0.8679387047886848
    - 0.8678635805845261
    - 0.868013821542263
    - 0.8801081702113152
    - 0.8915264457464218
    - 0.9015925452113152
    - 0.8962590172886848
    - 0.911959134042263
    - 0.9021183922886848
    - 0.9056490361690521
    - 0.907376803457737
    - 0.9138371422886848
    - 0.9217998832464218
    - 0.924954928457737
    - 0.9141376167535782
    - 0.9252554103732109
    - 0.9208233207464218
    - 0.9286358207464218
    - 0.9227764457464218
    - 0.9368239194154739
    - 0.9349459111690521
    - 0.9427584111690521
    - 0.9476412236690521
    - 0.9536508396267891
    - 0.9526742771267891
    - 0.9558293297886848
    - 0.9563551694154739
    - 0.9514723569154739
    - 0.957857571542263
    - 0.9634164646267891
    - 0.9670973569154739
    - 0.9714543297886848
    - 0.971529446542263
    - 0.9714543297886848
    - 0.9658203125
    - 0.9751352146267891
    - 0.9802433922886848
    - 0.9844501167535782
    - 0.9873046875
    - 0.9880558922886848
    - 0.9841496422886848
    - 0.9821965172886848
    - 0.9883563667535782
    - 0.9909855797886848
    - 0.9888070896267891
    - 0.9929387047886848
    - 0.9929387047886848
    - 0.9909855797886848
    - 0.9970703125
    - 0.9951171875
    - 0.998046875
    - 0.9951171875
    - 0.9970703125
    - 0.99609375
    - 0.9978215172886848
    - 0.9968449547886848
    - 0.998046875
    - 1.0
    - 0.998046875
    - 0.9990234375
    - 1.0
    - 0.9968449547886848
    - 0.9990234375
    - 0.998046875
    - 0.9987980797886848
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 0.9990234375
    - 0.9990234375
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
val_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: LinearEvalSVHN
validation_history:
  loss:
    total:
    - 2.2623540779639937
    - 2.21801063521155
    - 2.1729446197378226
    - 2.135145980736305
    - 2.1122823871415237
    - 2.092421858475126
    - 2.089126691736024
    - 2.0634582207120697
    - 2.076398222610868
    - 2.023265291904581
    - 2.0228236708147773
    - 2.010417973173076
    - 1.9890860565777482
    - 1.981685289021196
    - 1.9739380108899083
    - 1.9606543039453441
    - 1.9347042071408238
    - 1.9458762140109622
    - 1.9312094984383419
    - 1.917963952853762
    - 1.9914032940206856
    - 1.9514769110186347
    - 1.9144060693938156
    - 1.9171506433651364
    - 1.8969740764848118
    - 1.9276831540568122
    - 1.8999780272615368
    - 1.9419227879622887
    - 1.8738167368132492
    - 2.0074067300763625
    - 1.946569430417028
    - 1.972936870722935
    - 1.8170591592788696
    - 2.01227690639167
    - 1.8887546699622582
    - 1.8576399540079052
    - 2.0057831797106513
    - 1.886702015482146
    - 1.8823287651456635
    - 1.9098571867778384
    - 1.9794860667195813
    - 1.9227817901249589
    - 1.886787669412021
    - 1.972106777388474
    - 1.9478788026447953
    - 1.9597588592562183
    - 2.0374579491286444
    - 1.918336964886764
    - 2.023748342333169
    - 1.916612816268
    - 2.0007837332528213
    - 1.9818043667694618
    - 1.9982821591969193
    - 1.9736814951074535
    - 1.977202715544865
    - 2.0595906664585244
    - 1.972519932122066
    - 2.008198546952215
    - 1.9341492262379876
    - 2.271587077913613
    - 2.0744069835235335
    - 1.9257629760380448
    - 2.0443579924517663
    - 1.990144041077844
    - 2.018660311041207
    - 2.1234163929676186
    - 2.0704698439302116
    - 2.0322149252069406
    - 2.1086392505415557
    - 2.098098339705632
    - 2.1411379308536134
    - 2.0528634190559387
    - 2.083380436075145
    - 2.1954921463440202
    - 2.017447025611483
    - 2.139302305106459
    - 2.0301316791567308
    - 2.0225439791021675
    - 2.187802795706124
    - 2.1848935710972754
    - 2.118349825513774
    - 2.1242376874233115
    - 2.3009534848147424
    - 2.0534077348380255
    - 2.2075606358462365
    - 2.247266245299372
    - 2.1177030534579835
    - 2.2610125644453642
    - 2.202747014062158
    - 2.2475432280836434
    - 2.168823490882742
    - 2.2695632227535905
    - 2.3863061913128556
    - 2.315875086291083
    - 2.3731217877618196
    - 2.1566572045457773
    - 2.23514860868454
    - 2.3562450943322015
    - 2.3430923655115325
    - 2.2307052098471543
  metrics:
    svhn_top1_accuracy:
    - 0.19835668108586607
    - 0.24415409487896952
    - 0.26325431055036086
    - 0.25971623587197273
    - 0.2685434628149559
    - 0.2756465519296712
    - 0.26716056055036086
    - 0.2834590519296712
    - 0.2764547415848436
    - 0.2969288795158781
    - 0.3110811782294306
    - 0.30854885074599037
    - 0.30820761518231754
    - 0.3223599138958701
    - 0.32407507197610264
    - 0.326131465620008
    - 0.33538972714851645
    - 0.3376167385742582
    - 0.3470725576425421
    - 0.3467403018269046
    - 0.30335847725128307
    - 0.34377693975793905
    - 0.34879669547080994
    - 0.36408943965517243
    - 0.357381465620008
    - 0.3544181035510425
    - 0.3607489225165597
    - 0.3551544541942662
    - 0.37567349137931033
    - 0.3344827587234563
    - 0.35889906616046513
    - 0.3607489225165597
    - 0.4017690373905774
    - 0.3451598420225341
    - 0.3745510059184042
    - 0.3927801724137931
    - 0.3553969109880513
    - 0.38668283049402563
    - 0.388631465620008
    - 0.37843031616046513
    - 0.3744252873905774
    - 0.3810973424336006
    - 0.39830280172413796
    - 0.3787356322181636
    - 0.38166307478115474
    - 0.3918013649767843
    - 0.356636135228749
    - 0.40022449760601436
    - 0.3741199713328789
    - 0.40015265808023254
    - 0.3827406609880513
    - 0.37614044547080994
    - 0.3843211207924218
    - 0.4001167385742582
    - 0.387886135228749
    - 0.37502693975793905
    - 0.38347701163127507
    - 0.380818965620008
    - 0.40731860645886125
    - 0.3386494255271451
    - 0.3807830461140337
    - 0.40004489956230954
    - 0.3863056754243785
    - 0.39153196842506016
    - 0.3780172415848436
    - 0.38108836217173214
    - 0.3772449714356455
    - 0.3882183910443865
    - 0.3850574714356455
    - 0.3688577588262229
    - 0.37862787370024054
    - 0.3886943248839214
    - 0.39384877887265435
    - 0.35478627887265435
    - 0.3960308910443865
    - 0.3719558191710505
    - 0.39344468404506816
    - 0.4012302442871291
    - 0.3640445404011628
    - 0.3685255030105854
    - 0.3894665950331195
    - 0.39040948296415395
    - 0.36740301729276265
    - 0.41012033049402563
    - 0.37249461227449876
    - 0.36188936798736965
    - 0.4019306754243785
    - 0.37091415247012827
    - 0.37438038813656777
    - 0.3777478450331195
    - 0.3789960490218524
    - 0.3806483478381716
    - 0.3366289513892141
    - 0.3777478450331195
    - 0.3484195404011628
    - 0.40179597714851645
    - 0.3912535921253007
    - 0.3603358479409382
    - 0.36872306055036086
    - 0.38596443986070567
    svhn_top5_accuracy:
    - 0.6399245693765837
    - 0.6649784486869286
    - 0.6783494969894146
    - 0.674110991173777
    - 0.6940104170092221
    - 0.7072108480437048
    - 0.7185614222082598
    - 0.7348599135875702
    - 0.7387661635875702
    - 0.7543911635875702
    - 0.7605872842772253
    - 0.7588721267108259
    - 0.7711655888064154
    - 0.7811332612202085
    - 0.7765894398607057
    - 0.7873024426657578
    - 0.7895204743434643
    - 0.7916756467572574
    - 0.7961206898607057
    - 0.7959859915848436
    - 0.7857848416114676
    - 0.797036637519968
    - 0.7929238502321572
    - 0.7992546691976744
    - 0.7958512933089815
    - 0.801445761631275
    - 0.8022180312666399
    - 0.7934626433356055
    - 0.8043732036804331
    - 0.7843031605769848
    - 0.7927532329641539
    - 0.8062230605503609
    - 0.8203304594960706
    - 0.7723150140252607
    - 0.8084141519562952
    - 0.8159931754243785
    - 0.8033943967572574
    - 0.8138020829907779
    - 0.8144037353581396
    - 0.8080459771485164
    - 0.8066630743700882
    - 0.8144037353581396
    - 0.8178430312666399
    - 0.8096623564588612
    - 0.8021192530105854
    - 0.8204022985080193
    - 0.8015086208951885
    - 0.8238056754243785
    - 0.8049748560477947
    - 0.8238326146684843
    - 0.811144037493344
    - 0.8205010777917402
    - 0.8078753588528469
    - 0.8284841950597435
    - 0.8341415226459503
    - 0.8103268680901363
    - 0.8135686064588612
    - 0.8188487784615879
    - 0.8255208329907779
    - 0.7997575433089815
    - 0.8207076150795509
    - 0.8261943243700882
    - 0.8194234915848436
    - 0.8187500002055332
    - 0.8122485629443464
    - 0.8236979163926224
    - 0.8114044542970329
    - 0.8161907329641539
    - 0.818453663382037
    - 0.8050466950597435
    - 0.810533405377947
    - 0.818956537493344
    - 0.8195581898607057
    - 0.7849676722082598
    - 0.8185524426657578
    - 0.8118175288726543
    - 0.8154813215650362
    - 0.8226921691976744
    - 0.794163074986688
    - 0.8077047415848436
    - 0.8081088364124298
    - 0.8249820398873297
    - 0.8007363502321572
    - 0.8324622840716921
    - 0.8047413795158781
    - 0.8032956174735365
    - 0.8249191806234163
    - 0.7997575433089815
    - 0.8080459771485164
    - 0.8113415950331194
    - 0.8118175288726543
    - 0.8039960491246191
    - 0.7919450433089815
    - 0.8068336926657578
    - 0.7981770829907779
    - 0.8257273702785887
    - 0.8221892961140337
    - 0.802586207102085
    - 0.8076059623011227
    - 0.8194953305967922
