device: cuda
duration: 490.52413415908813
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  num_workers: 4
  save_freq: 30
loss:
  args: {}
  class: CrossEntropyLoss
metrics:
  svhn_top1_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 1
    class: Accuracy
  svhn_top5_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 5
    class: Accuracy
model:
  args:
    num_classes: 10
  class: ResNet50
optimizer:
  args:
    lr: 0.001
  class: Adam
train_dataset:
  args:
    num_labeled: 1000
    root: ./data/
    train_val_split: 0.9
  class: FineTuningTrainSVHN
train_history:
  loss:
    total:
    - 2.366588592529297
    - 1.8028694987297058
    - 1.4528195559978485
    - 1.081361785531044
    - 0.8092760667204857
    - 0.5758483298122883
    - 0.3731318414211273
    - 0.35011571273207664
    - 0.29451432451605797
    - 0.22453438863158226
    - 0.2080891728401184
    - 0.1616214457899332
    - 0.1458731982856989
    - 0.1286014961078763
    - 0.10279031004756689
    - 0.09769370872527361
    - 0.0867227977141738
    - 0.07962955813854933
    - 0.08098205272108316
    - 0.06734448438510299
    - 0.0531848284881562
    - 0.05949415313079953
    - 0.050363780348561704
    - 0.04773180454503745
    - 0.04276059800758958
    - 0.03700828459113836
    - 0.02965893258806318
    - 0.03771026141475886
    - 0.032903316896408796
    - 0.04377432505134493
    - 0.04024602135177702
    - 0.05350118409842253
    - 0.04822505498304963
    - 0.02561425999738276
    - 0.029398170940112323
    - 0.0240095216431655
    - 0.02707727369852364
    - 0.018117762869223952
    - 0.026464091090019792
    - 0.012865783355664462
    - 0.014800526085309684
    - 0.029226195998489857
    - 0.04682617587968707
    - 0.028184519615024328
    - 0.044751868466846645
    - 0.0468524566385895
    - 0.028205908252857625
    - 0.03222936287056655
    - 0.014364012400619686
    - 0.01878858305281028
    - 0.01641255005961284
    - 0.020048195277922787
    - 0.02234865928767249
    - 0.06886419288639445
    - 0.07877444091718644
    - 0.09344731899909675
    - 0.08474180335178971
    - 0.12834411161020398
    - 0.11039343196898699
    - 0.0769556148443371
    - 0.05708946590311825
    - 0.07248209929093719
    - 0.036337874247692525
    - 0.04744761227630079
    - 0.037043547723442316
    - 0.023584689828567207
    - 0.004845468225539662
    - 0.019872538396157324
    - 0.008717942022485659
    - 0.005985437717754394
    - 0.006614150799578056
    - 0.006530140730319545
    - 0.008192525176127674
    - 0.010259129805490375
    - 0.004600592204951681
    - 0.00698310234292876
    - 0.012452953902538866
    - 0.012375198683002964
    - 0.02740164817078039
    - 0.017381187266437337
    - 0.03108569176401943
    - 0.037908804253675044
    - 0.027697399840690196
    - 0.03309212072053924
    - 0.03889163280837238
    - 0.05114950559800491
    - 0.07516870647668839
    - 0.07715112389996648
    - 0.06580747803673148
    - 0.05129036458674818
    - 0.04241318517597392
    - 0.06061012204736471
    - 0.058756446931511164
    - 0.024212040472775698
    - 0.024146701209247112
    - 0.0316941742785275
    - 0.03251949777768459
    - 0.02287923390395008
    - 0.03540684295876417
    - 0.03950418523163535
  metrics:
    svhn_top1_accuracy:
    - 0.19749098643660545
    - 0.38739483058452606
    - 0.5141977146267891
    - 0.6716496422886848
    - 0.7310697138309479
    - 0.8262469917535782
    - 0.8916766792535782
    - 0.8864933922886848
    - 0.9035456702113152
    - 0.9293870180845261
    - 0.9350210353732109
    - 0.9485426694154739
    - 0.9538010805845261
    - 0.961763821542263
    - 0.9739332944154739
    - 0.9702524021267891
    - 0.9763371422886848
    - 0.9763371422886848
    - 0.9756610542535782
    - 0.9773137047886848
    - 0.9861027672886848
    - 0.9861027672886848
    - 0.982421875
    - 0.9878305271267891
    - 0.9890324547886848
    - 0.9868539646267891
    - 0.9905348569154739
    - 0.9870793297886848
    - 0.9890324547886848
    - 0.9824969917535782
    - 0.9861027672886848
    - 0.9807692319154739
    - 0.9880558922886848
    - 0.9929387047886848
    - 0.9909855797886848
    - 0.9939152672886848
    - 0.9927133396267891
    - 0.9970703125
    - 0.990234375
    - 0.9970703125
    - 0.99609375
    - 0.9929387047886848
    - 0.9897836521267891
    - 0.9900090172886848
    - 0.9851262047886848
    - 0.9827223569154739
    - 0.9929387047886848
    - 0.9890324547886848
    - 0.9978215172886848
    - 0.99609375
    - 0.9946664646267891
    - 0.9931640625
    - 0.9912109375
    - 0.981595553457737
    - 0.973482571542263
    - 0.9695012047886848
    - 0.9673227146267891
    - 0.9690504819154739
    - 0.9671724736690521
    - 0.9731820896267891
    - 0.9819711521267891
    - 0.9741586521267891
    - 0.9854266792535782
    - 0.9778395444154739
    - 0.9890324547886848
    - 0.9970703125
    - 1.0
    - 0.9939152672886848
    - 0.998046875
    - 0.9978215172886848
    - 0.998046875
    - 0.9970703125
    - 0.998046875
    - 0.9978215172886848
    - 0.9978215172886848
    - 0.998046875
    - 0.9948918297886848
    - 0.998046875
    - 0.9897836521267891
    - 0.9939152672886848
    - 0.990234375
    - 0.9892578125
    - 0.9892578125
    - 0.9912109375
    - 0.9873046875
    - 0.9800180271267891
    - 0.9769380986690521
    - 0.9751352146267891
    - 0.9746844917535782
    - 0.9821965172886848
    - 0.990234375
    - 0.9861027672886848
    - 0.9788161069154739
    - 0.9931640625
    - 0.9919621422886848
    - 0.9846754819154739
    - 0.9917367771267891
    - 0.9929387047886848
    - 0.9909855797886848
    - 0.9907602146267891
    svhn_top5_accuracy:
    - 0.6296574547886848
    - 0.8157301694154739
    - 0.902193509042263
    - 0.9504957944154739
    - 0.9770883396267891
    - 0.9785907417535782
    - 0.9897836521267891
    - 0.9931640625
    - 0.994140625
    - 0.998046875
    - 1.0
    - 0.9968449547886848
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 0.9987980797886848
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
val_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: LinearEvalSVHN
validation_history:
  loss:
    total:
    - 2.1029738352216523
    - 2.0155343228373033
    - 1.882373859142435
    - 1.5896850289969608
    - 1.707160273502613
    - 1.239653496906675
    - 1.3394485444858157
    - 1.5397257825423931
    - 1.7484048851605118
    - 1.3925636369606544
    - 1.6286564695424046
    - 1.5177406113723229
    - 1.4786947307915523
    - 1.4007206497521236
    - 1.7130652624985268
    - 1.4770045157136589
    - 1.4515632195719357
    - 1.555638294795464
    - 1.770032493204906
    - 1.8464794693322018
    - 1.4733060002326965
    - 1.6107723507387885
    - 2.0079174987201034
    - 1.6654295016979348
    - 1.5596660622235001
    - 1.7347411862735092
    - 1.6647500519094796
    - 1.6154726723144794
    - 1.6301306013403267
    - 1.5961976195203846
    - 1.705756020957026
    - 1.8473706471508946
    - 1.614306913367633
    - 1.531559052138493
    - 1.4154725979114402
    - 1.5520947164502636
    - 1.6123785910935238
    - 1.5483093354208717
    - 1.6844176362300742
    - 1.933183554945321
    - 1.6901528383123463
    - 1.8151387263988625
    - 2.298241132292254
    - 1.8076180712930088
    - 1.9595672837619125
    - 1.8270638770070569
    - 1.9472780309874436
    - 1.9040002041849597
    - 1.7126619692506462
    - 1.7969429369630485
    - 1.666516274213791
    - 1.6567503213882446
    - 1.6307847078504234
    - 1.5961630118304286
    - 1.8905213721867264
    - 2.0948436424649994
    - 1.8278988127050728
    - 1.7221279020967155
    - 1.5687357002291187
    - 1.8347573711954315
    - 1.5977678144800251
    - 1.542280425285471
    - 1.6202385569440907
    - 1.2820560161409706
    - 1.679914202155738
    - 1.499324885935619
    - 1.6190979182720184
    - 1.5263838387768844
    - 1.49877491285061
    - 1.4623366090758094
    - 1.521328596205547
    - 1.4042604678663715
    - 1.3597550556577485
    - 1.3797192604377353
    - 1.3953874039238896
    - 1.45788001500327
    - 1.481358442840905
    - 1.541550192339667
    - 1.737648805667614
    - 2.021328383478625
    - 1.7971083192989743
    - 1.5227872462108218
    - 1.6279007412236313
    - 1.6414892755705734
    - 1.726115231883937
    - 2.033085516814528
    - 1.6358646976536717
    - 1.911522036996381
    - 1.6809526517473419
    - 2.032238880108143
    - 1.6192351846859372
    - 1.7266284330137844
    - 1.962108581230558
    - 1.8967830600409672
    - 1.7532744613187066
    - 1.5428018672712918
    - 1.5051202835707829
    - 1.5118425961198478
    - 1.4963047093358532
    - 1.5402844907908604
  metrics:
    svhn_top1_accuracy:
    - 0.283800287493344
    - 0.3706896551724138
    - 0.4169181035510425
    - 0.5049928159549318
    - 0.5247306032427426
    - 0.6180765084151564
    - 0.6491199711273457
    - 0.6228268680901363
    - 0.6211386497678428
    - 0.6507812502055332
    - 0.6324533049402565
    - 0.6619252870822775
    - 0.6718211204841219
    - 0.6908494974004811
    - 0.6813487790781876
    - 0.7099766525728949
    - 0.6949263646684843
    - 0.697117457102085
    - 0.6901131467572574
    - 0.689304957102085
    - 0.7288074709218124
    - 0.7027029456763432
    - 0.6860003594694466
    - 0.705091594622053
    - 0.7310614226193264
    - 0.7209590519296711
    - 0.7185704019562952
    - 0.6990660922280674
    - 0.7239852732625501
    - 0.7137841232891741
    - 0.7084321122744988
    - 0.6803430318832397
    - 0.7222341956763432
    - 0.7402927443898958
    - 0.7460847702519647
    - 0.7406609191976744
    - 0.7311602008753809
    - 0.7419001439522053
    - 0.7341594829641539
    - 0.708225574986688
    - 0.7373563215650362
    - 0.7147898704841219
    - 0.6840786635875702
    - 0.6988595549402565
    - 0.7053250721816359
    - 0.7162446122744988
    - 0.7018947560211708
    - 0.7238146549668806
    - 0.7334141525728949
    - 0.7330818967572574
    - 0.7366558909416199
    - 0.7400592668303128
    - 0.7531249995889335
    - 0.7341594829641539
    - 0.7042564657227747
    - 0.6817169538859663
    - 0.7105154456763432
    - 0.7236889364390537
    - 0.7261763646684843
    - 0.7102819681167603
    - 0.7276939657227747
    - 0.7323724853581396
    - 0.7235183191710505
    - 0.7592492812666399
    - 0.7452406605769848
    - 0.7562140801857258
    - 0.739107399151243
    - 0.7526490657493986
    - 0.7601203301857258
    - 0.7656429594960706
    - 0.7589798847149158
    - 0.7676993536538091
    - 0.7763918823209303
    - 0.7710668105503609
    - 0.7676993536538091
    - 0.767429957102085
    - 0.7686422415848436
    - 0.765176005404571
    - 0.7468929599071371
    - 0.7340607036804331
    - 0.7393408767108259
    - 0.7597162353581396
    - 0.7431124284349638
    - 0.7275951864390537
    - 0.7235901581829992
    - 0.7085308905305534
    - 0.7368893674735365
    - 0.724595905377947
    - 0.7243534480703289
    - 0.7006106325264635
    - 0.7475305312666399
    - 0.7268857760676022
    - 0.7227729887797915
    - 0.7330100577453087
    - 0.749416307128709
    - 0.7594468388064154
    - 0.7697198277917402
    - 0.7709949715384121
    - 0.7651400864124298
    - 0.7572916663926224
    svhn_top5_accuracy:
    - 0.6976203301857258
    - 0.7912715519296711
    - 0.866603807128709
    - 0.8918911639986367
    - 0.9001795978381716
    - 0.9276311058422615
    - 0.931097342022534
    - 0.9328124995889335
    - 0.9237248558422615
    - 0.9345635771751404
    - 0.9283674564854852
    - 0.9336206892441059
    - 0.9334141519562952
    - 0.9433189651061749
    - 0.9385057471949478
    - 0.9401580454974339
    - 0.9446030886008822
    - 0.9417744248077787
    - 0.9433548851259823
    - 0.9401580454974339
    - 0.9471623558422615
    - 0.9436242816777065
    - 0.9357130023939856
    - 0.9455459765319166
    - 0.9491109909682438
    - 0.9444683903250201
    - 0.9470276575663994
    - 0.9463541661870891
    - 0.9508351293103449
    - 0.9492816092639134
    - 0.951104525862069
    - 0.9451418817043304
    - 0.9475664506698477
    - 0.9468211202785887
    - 0.9499551006432237
    - 0.9499191806234163
    - 0.9503591954708099
    - 0.9488415944165197
    - 0.9442977730570168
    - 0.9398886489457098
    - 0.9498563213595028
    - 0.9487068961406576
    - 0.9452047409682438
    - 0.9400233472215718
    - 0.9385057471949478
    - 0.9471623558422615
    - 0.9467582610146753
    - 0.9465158047347233
    - 0.9503951144629511
    - 0.9505298127388132
    - 0.9559536637931034
    - 0.9547413793103449
    - 0.9510686058422615
    - 0.9472970541181236
    - 0.942313217911227
    - 0.9431842668303128
    - 0.9471623558422615
    - 0.9397539506698477
    - 0.9450071834284683
    - 0.9445043103448276
    - 0.9495510058156376
    - 0.9523437495889335
    - 0.9550736351259823
    - 0.9572647265319166
    - 0.9499910196353649
    - 0.9553430316777065
    - 0.955145474137931
    - 0.9490840517241379
    - 0.9558189655172413
    - 0.9585129310344828
    - 0.9580729161870891
    - 0.9602280886008822
    - 0.9598599137931034
    - 0.9613415948275862
    - 0.9618803879310345
    - 0.9610721982758621
    - 0.9575341230836408
    - 0.9579022989190858
    - 0.9539960489190858
    - 0.9439295972215718
    - 0.9538972696353649
    - 0.958441092022534
    - 0.950628592022534
    - 0.9535290948275862
    - 0.9578394396551724
    - 0.9411997127121893
    - 0.9505298127388132
    - 0.9440642954974339
    - 0.9519127155172413
    - 0.9490122127121893
    - 0.9529543817043304
    - 0.9437948989457098
    - 0.9412356317043304
    - 0.9537625713595028
    - 0.9590158041181236
    - 0.9602280886008822
    - 0.9617726288992783
    - 0.9585757902983961
    - 0.9564565368767443
    - 0.9577316806234163
