device: cuda
duration: 488.7638955116272
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  num_workers: 4
  save_freq: 30
loss:
  args: {}
  class: CrossEntropyLoss
metrics:
  svhn_top1_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 1
    class: Accuracy
  svhn_top5_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 5
    class: Accuracy
model:
  args:
    num_classes: 10
  class: ResNet50
optimizer:
  args:
    lr: 0.001
  class: Adam
train_dataset:
  args:
    num_labeled: 1000
    root: ./data/
    train_val_split: 0.9
  class: FineTuningTrainSVHN
train_history:
  loss:
    total:
    - 2.3124265670776367
    - 2.2628528773784637
    - 2.233263313770294
    - 2.1997345983982086
    - 2.1266209483146667
    - 2.045073539018631
    - 2.007042109966278
    - 1.9417905509471893
    - 1.8793107122182846
    - 1.7449929863214493
    - 1.632405236363411
    - 1.5026273876428604
    - 1.4383535087108612
    - 1.2482596188783646
    - 1.0569923222064972
    - 0.9963951930403709
    - 0.9309310391545296
    - 0.7648421004414558
    - 0.6189118772745132
    - 0.5522644110023975
    - 0.42948924377560616
    - 0.41744040325284004
    - 0.372281514108181
    - 0.35999032855033875
    - 0.34097907319664955
    - 0.3004437945783138
    - 0.2346573993563652
    - 0.26049268804490566
    - 0.22511852346360683
    - 0.18665006197988987
    - 0.16077533643692732
    - 0.1559326509013772
    - 0.1296950513496995
    - 0.14821478445082903
    - 0.10811477620154619
    - 0.08419794496148825
    - 0.10360658448189497
    - 0.09237545263022184
    - 0.09694122150540352
    - 0.07871268736198545
    - 0.0911552282050252
    - 0.13102024234831333
    - 0.08878385275602341
    - 0.0816697720438242
    - 0.04205567273311317
    - 0.035169585258699954
    - 0.021383185405284166
    - 0.02108403787133284
    - 0.03290208618273027
    - 0.023237777641043067
    - 0.045901977602625266
    - 0.0359463628847152
    - 0.04575267864856869
    - 0.07147018355317414
    - 0.07935968111269176
    - 0.06600695196539164
    - 0.07592562073841691
    - 0.04753408010583371
    - 0.054962633177638054
    - 0.047232652781531215
    - 0.042444690072443336
    - 0.04233376553747803
    - 0.03421479498501867
    - 0.059235769091174006
    - 0.0765352500602603
    - 0.07175156939774752
    - 0.045051104854792356
    - 0.030442658928222954
    - 0.03890612116083503
    - 0.034709985833615065
    - 0.046913208439946175
    - 0.06184852961450815
    - 0.04540269181597978
    - 0.06900454801507294
    - 0.0358824604190886
    - 0.045668673468753695
    - 0.04313660482876003
    - 0.052234126487746835
    - 0.07579188537783921
    - 0.07264997600577772
    - 0.08149335533380508
    - 0.12488747388124466
    - 0.1268128273077309
    - 0.08960919873788953
    - 0.07281275989953429
    - 0.04011705738957971
    - 0.019502336013829336
    - 0.023971139104105532
    - 0.02089356549549848
    - 0.012811400723876432
    - 0.008196873153792694
    - 0.009988045276259072
    - 0.007156833293265663
    - 0.010967716501909308
    - 0.013286834917380475
    - 0.006324078800389543
    - 0.00526698627800215
    - 0.005480307088873815
    - 0.0070950175722828135
    - 0.013069736378383823
  metrics:
    svhn_top1_accuracy:
    - 0.16443810053169727
    - 0.1920823324471712
    - 0.19103064946830273
    - 0.22821514308452606
    - 0.2356520425528288
    - 0.2776442300528288
    - 0.27554086595773697
    - 0.3061147853732109
    - 0.3399188704788685
    - 0.3768780045211315
    - 0.4252554103732109
    - 0.4766376167535782
    - 0.48910757154226303
    - 0.5693359375
    - 0.6305588930845261
    - 0.667818509042263
    - 0.672025240957737
    - 0.738431490957737
    - 0.778470553457737
    - 0.8173076957464218
    - 0.863131009042263
    - 0.8677133396267891
    - 0.884915865957737
    - 0.8798076957464218
    - 0.8844651430845261
    - 0.902493990957737
    - 0.9092548042535782
    - 0.9066255986690521
    - 0.9214994013309479
    - 0.945162259042263
    - 0.9468149021267891
    - 0.949368990957737
    - 0.9512469917535782
    - 0.9551532417535782
    - 0.9639423042535782
    - 0.974459134042263
    - 0.9649188667535782
    - 0.9704777672886848
    - 0.9668719917535782
    - 0.9788161069154739
    - 0.9658954292535782
    - 0.9631911069154739
    - 0.9680739194154739
    - 0.9707782417535782
    - 0.9897836521267891
    - 0.9900090172886848
    - 0.99609375
    - 0.9948918297886848
    - 0.9870793297886848
    - 0.9921875
    - 0.990234375
    - 0.9921875
    - 0.9892578125
    - 0.9809945896267891
    - 0.9778395444154739
    - 0.9780649021267891
    - 0.9763371422886848
    - 0.9841496422886848
    - 0.985201321542263
    - 0.9807692319154739
    - 0.9851262047886848
    - 0.9890324547886848
    - 0.9909855797886848
    - 0.9824969917535782
    - 0.9764873832464218
    - 0.9770883396267891
    - 0.9836989194154739
    - 0.9909855797886848
    - 0.9895582944154739
    - 0.9892578125
    - 0.9831730797886848
    - 0.9749098569154739
    - 0.984375
    - 0.977388821542263
    - 0.9907602146267891
    - 0.9851262047886848
    - 0.9864032417535782
    - 0.9797926694154739
    - 0.9776141792535782
    - 0.977388821542263
    - 0.9714543297886848
    - 0.9592848569154739
    - 0.9678485542535782
    - 0.9734074547886848
    - 0.9807692319154739
    - 0.9853515625
    - 0.9951171875
    - 0.9939152672886848
    - 0.9936899021267891
    - 0.99609375
    - 0.998046875
    - 0.9978215172886848
    - 0.9990234375
    - 0.994140625
    - 0.9970703125
    - 0.9990234375
    - 0.9990234375
    - 0.9990234375
    - 0.9970703125
    - 0.99609375
    svhn_top5_accuracy:
    - 0.6022385805845261
    - 0.6376201957464218
    - 0.6428034827113152
    - 0.672025240957737
    - 0.7038010805845261
    - 0.7370793297886848
    - 0.7676532417535782
    - 0.7934194728732109
    - 0.8082932680845261
    - 0.8584735542535782
    - 0.8835637047886848
    - 0.910006009042263
    - 0.9124849736690521
    - 0.950045071542263
    - 0.9535005986690521
    - 0.9629657417535782
    - 0.9695012047886848
    - 0.9698016792535782
    - 0.9834735542535782
    - 0.9880558922886848
    - 0.9890324547886848
    - 0.9907602146267891
    - 0.9917367771267891
    - 0.9921875
    - 0.994140625
    - 0.9927133396267891
    - 0.9975961521267891
    - 0.9970703125
    - 0.998046875
    - 0.9990234375
    - 1.0
    - 0.9990234375
    - 1.0
    - 0.9990234375
    - 0.9990234375
    - 1.0
    - 0.9990234375
    - 0.9990234375
    - 0.9990234375
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 0.9990234375
    - 0.9990234375
    - 0.998046875
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
val_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: LinearEvalSVHN
validation_history:
  loss:
    total:
    - 2.5527753295569586
    - 2.2985715126169137
    - 2.283988796431443
    - 2.2810584923316695
    - 2.2356110893446823
    - 2.2249954116755517
    - 2.4241872285974435
    - 2.160764957296437
    - 2.098084647079994
    - 2.1289954802085616
    - 2.2305358093360375
    - 1.9963794638370644
    - 2.1503773804368644
    - 2.4117412361605415
    - 1.5630415657470966
    - 1.8167319585537087
    - 1.5199797379559483
    - 1.468242382181102
    - 1.4717677626116523
    - 1.4548355895897438
    - 1.2424183600935443
    - 1.310326131253407
    - 1.4873456492506225
    - 1.3330551036472977
    - 1.1207614243030548
    - 1.0257530572085545
    - 1.6273366993871228
    - 1.6255134323547626
    - 1.6251447724884953
    - 1.0895795205543781
    - 1.3869007060240055
    - 1.3630813041637684
    - 1.3218986232732903
    - 1.3960463009003936
    - 1.190228678542992
    - 1.2418389546460118
    - 1.3499593724464547
    - 1.5562765017665665
    - 1.7126213980132137
    - 1.7306295818295971
    - 1.8774657331663986
    - 1.6481574856001755
    - 1.3912165421864082
    - 1.2041814499374093
    - 1.3028404925917756
    - 1.2070179120476903
    - 1.1833272743327865
    - 1.1910530847722087
    - 1.443317759396701
    - 1.461091360141491
    - 1.4238240795916524
    - 1.4725099843123863
    - 1.3516766768077324
    - 2.1028380065128722
    - 1.605680102932042
    - 1.9437297058516536
    - 1.7469318642698486
    - 1.5340317785739899
    - 1.4611921238488164
    - 1.5821005666050418
    - 1.432351193679818
    - 1.390618792895613
    - 1.5090582072734833
    - 1.3123757345923062
    - 1.7286291071053208
    - 1.59488152378592
    - 1.3952227034445466
    - 1.4857031548845356
    - 1.5659271776676178
    - 1.397483514300708
    - 1.6636971430531864
    - 1.5657231386365562
    - 1.4730654042856446
    - 1.2817918103316734
    - 1.6392529293380935
    - 1.2952458694063385
    - 1.3063790109650841
    - 1.4719398586914456
    - 1.7646075959863334
    - 2.088694102805236
    - 2.3041112854562957
    - 1.8184700412996884
    - 1.6824304995865658
    - 1.5474390038128556
    - 1.5996868487062126
    - 1.2494529131157646
    - 1.2652942867114627
    - 1.2762659554337632
    - 1.3425076336696231
    - 1.2926494782340938
    - 1.3271884054973209
    - 1.331074535332877
    - 1.4734232204741444
    - 1.3227159167672027
    - 1.2997354078909447
    - 1.3087560796532138
    - 1.3857422440216458
    - 1.3497043015628025
    - 1.7743851378046234
    - 1.9230515628025449
  metrics:
    svhn_top1_accuracy:
    - 0.16787895123506413
    - 0.18185165241874499
    - 0.19148706901690055
    - 0.19081357763759021
    - 0.22623922418931436
    - 0.22381465522379712
    - 0.19233117817804732
    - 0.2343660202519647
    - 0.2619791668036888
    - 0.30043103468829185
    - 0.3429328305967923
    - 0.33858656626323175
    - 0.27672413813656777
    - 0.29568965527518043
    - 0.5203753596749799
    - 0.4908494969894146
    - 0.5666487073076183
    - 0.5752693969627907
    - 0.5918193243700882
    - 0.6173311780238974
    - 0.6755028737002405
    - 0.6966056032427426
    - 0.6475754308289495
    - 0.6787266525728949
    - 0.7063397991246191
    - 0.7316002157227747
    - 0.6888649422546913
    - 0.6900772267374499
    - 0.6659033760942262
    - 0.7490122123011227
    - 0.7204920978381716
    - 0.7361530168303128
    - 0.7422772985080193
    - 0.7514727012864475
    - 0.7566540950331194
    - 0.7590786639986367
    - 0.7258081898607057
    - 0.7259159478647955
    - 0.7122395829907779
    - 0.6976562502055332
    - 0.6976203301857258
    - 0.720797413382037
    - 0.7357489220027266
    - 0.7770653737002405
    - 0.7833333334018444
    - 0.7857938213595028
    - 0.7861979161870891
    - 0.7899335489190858
    - 0.7704022989190858
    - 0.772692169608741
    - 0.780504669608741
    - 0.7611709771485164
    - 0.7757902299535686
    - 0.6967133622744988
    - 0.7442977726459503
    - 0.732650861657899
    - 0.7258081898607057
    - 0.7562500002055332
    - 0.7571300288726543
    - 0.7597880743700882
    - 0.778753592022534
    - 0.7610003588528469
    - 0.7492816088528469
    - 0.7756824709218124
    - 0.7227101295158781
    - 0.7400592668303128
    - 0.7660560340716921
    - 0.7568247123011227
    - 0.7515355605503609
    - 0.7646012933089815
    - 0.7668642237268645
    - 0.7556124278183641
    - 0.7602011489457098
    - 0.7756914506698477
    - 0.7387122840716921
    - 0.7822198271751404
    - 0.7842403013130714
    - 0.7605962640252607
    - 0.7421785202519647
    - 0.7099137933089815
    - 0.6941900140252607
    - 0.7308279450597435
    - 0.7302891519562952
    - 0.7458153737002405
    - 0.7471982754510025
    - 0.7882094105769848
    - 0.7947108478381716
    - 0.7930316092639134
    - 0.7828573995623095
    - 0.7996946840450682
    - 0.8040768678846031
    - 0.8026311058422615
    - 0.7808728444165197
    - 0.8041127868767443
    - 0.7954202582096231
    - 0.7945132902983961
    - 0.7968031609880513
    - 0.8056932471949478
    - 0.7637302443898958
    - 0.7691900144363272
    svhn_top5_accuracy:
    - 0.6102999284349638
    - 0.6187140808023256
    - 0.6303609917903769
    - 0.6440732756565357
    - 0.6402298849204491
    - 0.6723599135875702
    - 0.6288793107558941
    - 0.7097701152850842
    - 0.7292654452652767
    - 0.7634788073342422
    - 0.80107758579583
    - 0.8108656611935846
    - 0.7852101295158781
    - 0.7680316094694466
    - 0.9028376433356055
    - 0.9020025144363272
    - 0.9255118534482759
    - 0.9241289506698477
    - 0.9302262931034483
    - 0.9391163793103449
    - 0.9391792385742582
    - 0.9409303161604651
    - 0.9386404454708099
    - 0.9457165948275862
    - 0.9496228448275862
    - 0.9555495689655172
    - 0.9489493534482759
    - 0.9413703299801925
    - 0.9471623558422615
    - 0.9595905172413793
    - 0.9484105603448276
    - 0.9568965517241379
    - 0.9587823275862069
    - 0.9527209051724138
    - 0.9601293103448276
    - 0.9571659482758621
    - 0.9544719827586207
    - 0.9523168103448276
    - 0.9542025862068966
    - 0.9427173127388132
    - 0.9509698275862069
    - 0.9513739224137931
    - 0.9500269396551724
    - 0.9612068965517241
    - 0.9633620689655172
    - 0.9674030172413793
    - 0.9665948275862069
    - 0.9676724137931034
    - 0.9598599137931034
    - 0.9579741379310345
    - 0.9617456896551724
    - 0.9571659482758621
    - 0.9606681034482759
    - 0.9504310344827587
    - 0.9612068965517241
    - 0.9547054592905373
    - 0.9539331896551724
    - 0.9571659482758621
    - 0.9617456896551724
    - 0.9601293103448276
    - 0.9614762931034483
    - 0.9595545972215718
    - 0.9605334051724138
    - 0.9640355603448276
    - 0.9489493534482759
    - 0.9624191810344828
    - 0.9652478448275862
    - 0.9605334051724138
    - 0.9558189655172413
    - 0.9626885775862069
    - 0.9618803879310345
    - 0.9574353448275862
    - 0.9593211206896551
    - 0.9603987068965517
    - 0.9493534482758621
    - 0.9613415948275862
    - 0.9652478448275862
    - 0.9576688213595028
    - 0.9546066810344828
    - 0.9528196834284683
    - 0.9501616379310345
    - 0.9543372844827587
    - 0.9593211206896551
    - 0.9651131465517241
    - 0.9575700431034483
    - 0.9664601293103449
    - 0.9655172413793104
    - 0.9659213362068966
    - 0.9636314655172413
    - 0.9688846982758621
    - 0.9700969827586207
    - 0.9675377155172413
    - 0.9626885775862069
    - 0.9660560344827587
    - 0.9678071120689655
    - 0.9665948275862069
    - 0.9682112068965517
    - 0.9684806034482759
    - 0.96484375
    - 0.9562230603448276
