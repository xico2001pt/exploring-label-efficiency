device: cuda
duration: 1891.7994520664215
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  num_workers: 4
  save_freq: 30
loss:
  args: {}
  class: CrossEntropyLoss
metrics:
  svhn_top1_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 1
    class: Accuracy
  svhn_top5_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 5
    class: Accuracy
model:
  args:
    num_classes: 10
  class: ResNet50
optimizer:
  args:
    lr: 0.001
  class: Adam
train_dataset:
  args:
    num_labeled: 500
    root: ./data/
    train_val_split: 0.9
  class: FineTuningTrainSVHN
train_history:
  loss:
    total:
    - 2.3272597789764404
    - 1.8558878004550934
    - 1.557221233844757
    - 1.2521281838417053
    - 1.0110205262899399
    - 0.7898636162281036
    - 0.6063373535871506
    - 0.45440123975276947
    - 0.37056172639131546
    - 0.2553098015487194
    - 0.18524019792675972
    - 0.12448779121041298
    - 0.08215868473052979
    - 0.0648125484585762
    - 0.053127150516957045
    - 0.04826596798375249
    - 0.0369264273904264
    - 0.021843474358320236
    - 0.03301948681473732
    - 0.024519493337720633
    - 0.021449605002999306
    - 0.030647076899185777
    - 0.018966925563290715
    - 0.031985513400286436
    - 0.019777370151132345
    - 0.039694664534181356
    - 0.039771143114194274
    - 0.04949476779438555
    - 0.03948551067151129
    - 0.07672961778007448
    - 0.10026844823732972
    - 0.05884683784097433
    - 0.05448480136692524
    - 0.0684626679867506
    - 0.03282969840802252
    - 0.03404831560328603
    - 0.0372789092361927
    - 0.04117625718936324
    - 0.03403217764571309
    - 0.015629308065399528
    - 0.019430963788181543
    - 0.012483830680139363
    - 0.017803631955757737
    - 0.01421148149529472
    - 0.007414054707624018
    - 0.004832227772567421
    - 0.016136691090650856
    - 0.0222084901179187
    - 0.005977104010526091
    - 0.01756998768541962
    - 0.04751931154169142
    - 0.01314526266651228
    - 0.03481360571458936
    - 0.03343099122866988
    - 0.020442639710381627
    - 0.023462136276066303
    - 0.0505955929402262
    - 0.03915404551662505
    - 0.08933921530842781
    - 0.046810735017061234
    - 0.03278873395174742
    - 0.02888241922482848
    - 0.035888776415959
    - 0.015000604558736086
    - 0.026970605948008597
    - 0.03896419098600745
    - 0.036672461312264204
    - 0.01485903945285827
    - 0.030378889408893883
    - 0.0184895065613091
    - 0.027411605115048587
    - 0.02070416184142232
    - 0.016766341985203326
    - 0.014965026639401913
    - 0.010223975987173617
    - 0.012500308977905661
    - 0.029686444206163287
    - 0.023583468806464225
    - 0.004622836771886796
    - 0.03191339178010821
    - 0.012978231214219704
    - 0.01458147494122386
    - 0.019284119684016332
    - 0.0074145701073575765
    - 0.0057652745163068175
    - 0.016350239398889244
    - 0.01148209918756038
    - 0.0038331554387696087
    - 0.005423305789008737
    - 0.002321004867553711
    - 0.0016075608291430399
    - 0.001747412927215919
    - 0.00271938880905509
    - 0.0012648843330680393
    - 0.0006181292555993423
    - 0.0008438359000138007
    - 0.0005303190846461803
    - 0.0010315434847143479
    - 0.0002547306976339314
    - 0.0002436440463498002
  metrics:
    svhn_top1_accuracy:
    - 0.18440193682909012
    - 0.33755388110876083
    - 0.47790948301553726
    - 0.5838496834039688
    - 0.6458108872175217
    - 0.7512122839689255
    - 0.8114224076271057
    - 0.8531788736581802
    - 0.8893453627824783
    - 0.9276670217514038
    - 0.9566271603107452
    - 0.9740032255649567
    - 0.9794585108757019
    - 0.9839709103107452
    - 0.990234375
    - 0.9917834103107452
    - 0.99609375
    - 0.9958917051553726
    - 0.9917834103107452
    - 0.9956896603107452
    - 0.9939385801553726
    - 0.9939385801553726
    - 0.998046875
    - 0.994140625
    - 0.9958917051553726
    - 0.9919854551553726
    - 0.9874730557203293
    - 0.9917834103107452
    - 0.9857219755649567
    - 0.9818157255649567
    - 0.9700969755649567
    - 0.9820177853107452
    - 0.9878771603107452
    - 0.9800646603107452
    - 0.9900323301553726
    - 0.9839709103107452
    - 0.9919854551553726
    - 0.9857219755649567
    - 0.9919854551553726
    - 0.998046875
    - 0.9958917051553726
    - 0.9978448301553726
    - 0.9939385801553726
    - 0.9958917051553726
    - 1.0
    - 1.0
    - 0.9958917051553726
    - 0.9935344755649567
    - 1.0
    - 0.9958917051553726
    - 0.9870689660310745
    - 0.9937365353107452
    - 0.9876751005649567
    - 0.9900323301553726
    - 0.994140625
    - 0.9919854551553726
    - 0.9857219755649567
    - 0.9837688505649567
    - 0.9720501005649567
    - 0.9837688505649567
    - 0.9921875
    - 0.990234375
    - 0.9859240353107452
    - 0.9958917051553726
    - 0.9919854551553726
    - 0.9861260801553726
    - 0.9839709103107452
    - 0.9937365353107452
    - 0.9939385801553726
    - 0.994140625
    - 0.984375
    - 0.9939385801553726
    - 0.9958917051553726
    - 0.9958917051553726
    - 0.9978448301553726
    - 0.998046875
    - 0.99609375
    - 0.990234375
    - 1.0
    - 0.9937365353107452
    - 0.994140625
    - 0.998046875
    - 0.9937365353107452
    - 0.998046875
    - 0.998046875
    - 0.9939385801553726
    - 0.99609375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    svhn_top5_accuracy:
    - 0.5732085108757019
    - 0.8290005326271057
    - 0.8887392282485962
    - 0.9542699307203293
    - 0.9757543057203293
    - 0.9841729551553726
    - 0.9958917051553726
    - 0.9939385801553726
    - 0.998046875
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 1.0
    - 0.9956896603107452
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
val_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: LinearEvalSVHN
validation_history:
  loss:
    total:
    - 2.1300454221922775
    - 2.0104100334233252
    - 2.1555274724960327
    - 2.0091948057043143
    - 1.8525052605004146
    - 1.7322712890033065
    - 1.5313407182693481
    - 1.53966030889544
    - 1.9344878402249566
    - 1.6768488873695504
    - 1.8181510485451797
    - 1.7754841765453075
    - 1.7264547049999237
    - 1.7705947386807408
    - 1.8726924041221882
    - 1.9161722536744743
    - 2.0278032134319175
    - 2.0008451116496118
    - 1.9191427703561454
    - 2.1766908168792725
    - 2.0989330225977403
    - 2.0924177128693153
    - 2.5016794307478545
    - 2.204219943490522
    - 2.1617623156514663
    - 2.1390481282924783
    - 2.500917481965032
    - 2.5193688992796273
    - 2.7378118120390793
    - 3.038774471858452
    - 2.8559047846958556
    - 2.52897781339185
    - 2.6792548977095505
    - 2.199435534148381
    - 2.145606852810958
    - 2.143010427211893
    - 2.010367694599875
    - 1.8981872098199253
    - 1.9025592824508404
    - 1.884237254488057
    - 1.9008162237446884
    - 1.926277440169762
    - 1.9905999734483917
    - 1.9759016674140404
    - 1.9649409528436332
    - 1.9795566591723213
    - 2.2375983246441544
    - 2.6849654542988746
    - 2.576038864152185
    - 2.388716888838801
    - 2.0437142417348664
    - 2.307020567614457
    - 2.1518745751216493
    - 2.1191770434379578
    - 2.329402578288111
    - 3.4387895485450484
    - 2.886346015436896
    - 2.412311418303128
    - 2.464152821179094
    - 2.268071941260634
    - 2.1940496193951575
    - 2.4061325192451477
    - 2.486151931614711
    - 2.5978092695104666
    - 2.3414986894048493
    - 2.414387612507261
    - 2.4196082846871736
    - 2.3733469617777856
    - 2.160687132128354
    - 2.078145717752391
    - 1.8804614543914795
    - 1.9192381583411118
    - 1.9966179954594578
    - 2.2847921478337256
    - 2.47967646450832
    - 2.4549079825138223
    - 2.5263455160732926
    - 2.536735577829953
    - 2.580499725095157
    - 2.4126770105855218
    - 2.183770640143033
    - 2.2691250731205117
    - 2.1717786131234003
    - 2.2213424279772003
    - 2.2422757888662406
    - 1.958538439767114
    - 1.8777514521417946
    - 1.9047352404429996
    - 1.8804456838246049
    - 1.8644489152678128
    - 1.8355490668066616
    - 1.8467428386211395
    - 1.860136546965303
    - 1.8730025630572746
    - 1.8974810078226287
    - 1.9208995340199306
    - 1.9230551236662372
    - 1.9039901649129802
    - 1.900133724870353
    - 1.8913206653348331
  metrics:
    svhn_top1_accuracy:
    - 0.29683908049402563
    - 0.30650143685012027
    - 0.3518588363096632
    - 0.39472880753977546
    - 0.4554867097016039
    - 0.4663882902983961
    - 0.5460398711007217
    - 0.5528107038859663
    - 0.5080190372878107
    - 0.5711296694032078
    - 0.5756734917903769
    - 0.5899874280238974
    - 0.6128861349204491
    - 0.6127873566643945
    - 0.6067169545025661
    - 0.6100844113991178
    - 0.6115032331696872
    - 0.6266253590583801
    - 0.6373653021352045
    - 0.6045348418170008
    - 0.6133979887797915
    - 0.6278735635609463
    - 0.5946030894230152
    - 0.618543462506656
    - 0.6224856325264635
    - 0.6410111353315157
    - 0.6129579739323978
    - 0.6179777301591018
    - 0.5854436066643945
    - 0.5588002872878107
    - 0.5741918107558941
    - 0.6064834769429832
    - 0.5827676006432237
    - 0.6299928159549318
    - 0.627334770457498
    - 0.6338721267108259
    - 0.6585219111935846
    - 0.6624281611935846
    - 0.6548491377255012
    - 0.6618893680901363
    - 0.6639098422280674
    - 0.6615211922546913
    - 0.6600035922280674
    - 0.6746857042970329
    - 0.6746857042970329
    - 0.670070042897915
    - 0.6476023711007217
    - 0.610120330391259
    - 0.626858836617963
    - 0.6427981319098637
    - 0.6665409484813953
    - 0.6361619974004811
    - 0.6478807474004811
    - 0.6478089083885324
    - 0.6565373560477947
    - 0.5777298849204491
    - 0.6043013652850842
    - 0.6336655894230152
    - 0.6317169542970329
    - 0.6571030894230152
    - 0.6318426728248596
    - 0.6378053159549318
    - 0.6685973416114676
    - 0.6661727726459503
    - 0.6844558191710505
    - 0.6633620693765837
    - 0.6612428159549318
    - 0.6521551722082598
    - 0.6664331894496391
    - 0.6571659486869286
    - 0.6804058911471531
    - 0.6875448997678428
    - 0.6910201146684843
    - 0.6612787359747393
    - 0.6418103452386528
    - 0.6422862790781876
    - 0.6430675284615879
    - 0.6511853450331194
    - 0.6502693963461909
    - 0.6609734194032078
    - 0.6868714083885324
    - 0.6866379308289495
    - 0.6961655894230152
    - 0.694782686644587
    - 0.6850215515186047
    - 0.7049568963461909
    - 0.7005118532427426
    - 0.6983297415848436
    - 0.7051634336340016
    - 0.7108207612202085
    - 0.7161099139986367
    - 0.7200880030105854
    - 0.7219737788726543
    - 0.7274964081829992
    - 0.7254400140252607
    - 0.7257094105769848
    - 0.7262122846882919
    - 0.7279633622744988
    - 0.7276939657227747
    - 0.7286727726459503
    svhn_top5_accuracy:
    - 0.6989673129443464
    - 0.7610003588528469
    - 0.800332255404571
    - 0.830540589217482
    - 0.8629040944165197
    - 0.889879669608741
    - 0.9042564651061749
    - 0.9105872840716921
    - 0.8965068243700882
    - 0.9120689651061749
    - 0.9157058185544508
    - 0.9142600575397755
    - 0.924290589217482
    - 0.9208243530372093
    - 0.9198814651061749
    - 0.9201149426657578
    - 0.9128771547613472
    - 0.9231142237268645
    - 0.9286368530372093
    - 0.9206896547613472
    - 0.9279005023939856
    - 0.9297862782560545
    - 0.9195761495623095
    - 0.9253053161604651
    - 0.9260147265319166
    - 0.9291127868767443
    - 0.9151670254510025
    - 0.9194773702785887
    - 0.9112607754510025
    - 0.9087015082096231
    - 0.9200880023939856
    - 0.919989224137931
    - 0.9186691806234163
    - 0.9286997123011227
    - 0.9273886495623095
    - 0.9330549568965517
    - 0.935479525862069
    - 0.9365571120689655
    - 0.9346713362068966
    - 0.9336925282560545
    - 0.9338631465517241
    - 0.9349407327586207
    - 0.9351742092905373
    - 0.9375987782560545
    - 0.935775861657899
    - 0.936144037493344
    - 0.9320671691976744
    - 0.920285559933761
    - 0.9253053161604651
    - 0.9256106317043304
    - 0.9330549568965517
    - 0.9266522989190858
    - 0.9351742092905373
    - 0.9354436058422615
    - 0.9283674564854852
    - 0.9109554599071371
    - 0.9172862788726543
    - 0.9179328299801925
    - 0.9237877151061749
    - 0.9319414506698477
    - 0.9282058189655172
    - 0.9266522989190858
    - 0.9318067523939856
    - 0.9275951868501203
    - 0.9343301006432237
    - 0.9396192523939856
    - 0.9348060344827587
    - 0.9277658041181236
    - 0.9346354161870891
    - 0.9377334765319166
    - 0.9374640799801925
    - 0.9397539506698477
    - 0.9381375713595028
    - 0.9317708334018444
    - 0.9279992816777065
    - 0.9280352006698477
    - 0.92578125
    - 0.9301903730836408
    - 0.9273976293103449
    - 0.9329202586206896
    - 0.9390804592905373
    - 0.9396551724137931
    - 0.9426185344827587
    - 0.9428879310344828
    - 0.9378681748077787
    - 0.9430226293103449
    - 0.9437948989457098
    - 0.9424479161870891
    - 0.9466235627388132
    - 0.948105243773296
    - 0.9479705454974339
    - 0.9477011489457098
    - 0.9495869248077787
    - 0.9498922413793104
    - 0.9496228448275862
    - 0.9488146551724138
    - 0.9493534482758621
    - 0.9488146551724138
    - 0.9493534482758621
    - 0.9500269396551724
