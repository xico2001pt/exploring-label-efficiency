device: cuda
duration: 1860.2247807979584
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  num_workers: 4
  save_freq: 30
loss:
  args: {}
  class: CrossEntropyLoss
metrics:
  svhn_top1_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 1
    class: Accuracy
  svhn_top5_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 5
    class: Accuracy
model:
  args:
    num_classes: 10
  class: ResNet50
optimizer:
  args:
    lr: 0.001
  class: Adam
train_dataset:
  args:
    num_labeled: 500
    root: ./data/
    train_val_split: 0.9
  class: FineTuningTrainSVHN
train_history:
  loss:
    total:
    - 2.3590136766433716
    - 2.236327052116394
    - 2.1622881293296814
    - 2.1174610257148743
    - 2.004380375146866
    - 1.9362083077430725
    - 1.8590171933174133
    - 1.7495501339435577
    - 1.5750746130943298
    - 1.405631184577942
    - 1.312470257282257
    - 1.118556410074234
    - 1.1146483421325684
    - 0.9919337630271912
    - 0.8904680907726288
    - 0.7290086895227432
    - 0.6011078506708145
    - 0.5856344699859619
    - 0.614177942276001
    - 0.5213672965764999
    - 0.4703841879963875
    - 0.45435890555381775
    - 0.3698285147547722
    - 0.30064669251441956
    - 0.2455407716333866
    - 0.221950963139534
    - 0.24941666424274445
    - 0.20768874511122704
    - 0.167683532461524
    - 0.1846430040895939
    - 0.20814160630106926
    - 0.12395036779344082
    - 0.12685395404696465
    - 0.1524067036807537
    - 0.1039507482200861
    - 0.10330355633050203
    - 0.144676779396832
    - 0.10994879715144634
    - 0.1048050969839096
    - 0.11314992047846317
    - 0.26465853303670883
    - 0.13996786251664162
    - 0.1818390153348446
    - 0.21158708166331053
    - 0.14715644158422947
    - 0.08322574198246002
    - 0.18161664344370365
    - 0.07917983084917068
    - 0.10757028497755527
    - 0.06250237580388784
    - 0.12145942356437445
    - 0.12920509465038776
    - 0.0982830636203289
    - 0.11614091880619526
    - 0.08274979144334793
    - 0.057870383374392986
    - 0.060075508896261454
    - 0.02303771348670125
    - 0.10301460092887282
    - 0.04294765554368496
    - 0.05496495636180043
    - 0.036404010839760303
    - 0.05862975539639592
    - 0.022711925208568573
    - 0.04646895080804825
    - 0.02704288309905678
    - 0.021191241219639778
    - 0.03687437134794891
    - 0.04343978757970035
    - 0.03428173274733126
    - 0.04103052895516157
    - 0.039417829480953515
    - 0.04453337984159589
    - 0.03159111790591851
    - 0.02828278671950102
    - 0.024422027869150043
    - 0.02087893837597221
    - 0.011119265749584883
    - 0.012700949097052217
    - 0.011069658561609685
    - 0.006313367921393365
    - 0.004800306865945458
    - 0.0018997688312083483
    - 0.004059447965119034
    - 0.0050012170686386526
    - 0.006362476138747297
    - 0.005382000614190474
    - 0.016795647388789803
    - 0.0037942896015010774
    - 0.012766913627274334
    - 0.038686994987074286
    - 0.004392188333440572
    - 0.022249553119763732
    - 0.012115147081203759
    - 0.02197919611353427
    - 0.0188606686424464
    - 0.028775470156688243
    - 0.02230265410616994
    - 0.007989964913576841
    - 0.024053460801951587
  metrics:
    svhn_top1_accuracy:
    - 0.14116379246115685
    - 0.17921605706214905
    - 0.22124191746115685
    - 0.23666486889123917
    - 0.2961341589689255
    - 0.31472252309322357
    - 0.36745689809322357
    - 0.4053071141242981
    - 0.47615840286016464
    - 0.5216864198446274
    - 0.5653286576271057
    - 0.6088362038135529
    - 0.5938173532485962
    - 0.6450700461864471
    - 0.7044046372175217
    - 0.7392241358757019
    - 0.8039466589689255
    - 0.8314924538135529
    - 0.7945177853107452
    - 0.8346578627824783
    - 0.8465786576271057
    - 0.857421875
    - 0.8790409415960312
    - 0.9131869673728943
    - 0.917497307062149
    - 0.933122307062149
    - 0.9200565665960312
    - 0.9405307173728943
    - 0.9575700461864471
    - 0.9438981711864471
    - 0.9220096915960312
    - 0.9515086263418198
    - 0.9634294211864471
    - 0.9542699307203293
    - 0.9591190665960312
    - 0.9742052853107452
    - 0.9540678858757019
    - 0.9642376005649567
    - 0.9642376005649567
    - 0.9735991358757019
    - 0.9319773763418198
    - 0.9636314660310745
    - 0.9408001005649567
    - 0.9393857717514038
    - 0.9352774769067764
    - 0.9740032255649567
    - 0.935075432062149
    - 0.9839709103107452
    - 0.9698949307203293
    - 0.9837688505649567
    - 0.9667295217514038
    - 0.9567618519067764
    - 0.9677397608757019
    - 0.9538658410310745
    - 0.9677397608757019
    - 0.9839709103107452
    - 0.9837688505649567
    - 0.9921875
    - 0.9706357717514038
    - 0.9839709103107452
    - 0.9900323301553726
    - 0.9839709103107452
    - 0.9833647608757019
    - 0.994140625
    - 0.9835668057203293
    - 0.9896282255649567
    - 0.99609375
    - 0.9876751005649567
    - 0.9874730557203293
    - 0.9898302853107452
    - 0.9878771603107452
    - 0.9853178858757019
    - 0.986328125
    - 0.9939385801553726
    - 0.9880792051553726
    - 0.994140625
    - 0.9921875
    - 0.998046875
    - 0.998046875
    - 0.99609375
    - 1.0
    - 1.0
    - 1.0
    - 0.998046875
    - 0.9978448301553726
    - 0.9956896603107452
    - 0.998046875
    - 0.9978448301553726
    - 0.9978448301553726
    - 0.9956896603107452
    - 0.9880792051553726
    - 1.0
    - 0.9919854551553726
    - 0.99609375
    - 0.9939385801553726
    - 0.9919854551553726
    - 0.9958917051553726
    - 0.9939385801553726
    - 0.9978448301553726
    - 0.9937365353107452
    svhn_top5_accuracy:
    - 0.5706492513418198
    - 0.664533942937851
    - 0.7116783410310745
    - 0.7404364198446274
    - 0.7794989198446274
    - 0.7932381480932236
    - 0.8358028084039688
    - 0.8522359877824783
    - 0.8897494673728943
    - 0.9205953627824783
    - 0.9337284415960312
    - 0.9497575461864471
    - 0.9478044211864471
    - 0.9777074307203293
    - 0.9694908410310745
    - 0.990234375
    - 0.9939385801553726
    - 0.98828125
    - 0.9857219755649567
    - 0.9919854551553726
    - 0.994140625
    - 0.9937365353107452
    - 0.998046875
    - 0.9978448301553726
    - 1.0
    - 0.9978448301553726
    - 1.0
    - 1.0
    - 0.9978448301553726
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 0.998046875
    - 1.0
    - 0.994140625
    - 1.0
    - 1.0
    - 0.9978448301553726
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9978448301553726
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
val_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: LinearEvalSVHN
validation_history:
  loss:
    total:
    - 2.2667665276034126
    - 2.2880302955364358
    - 2.262678310788911
    - 2.271719583149614
    - 2.322229130514737
    - 2.2100673543995826
    - 2.254595526333513
    - 2.2306457203010033
    - 2.328661659668232
    - 2.1842161437560774
    - 2.2793222049186967
    - 2.4019730707694746
    - 2.641327640105938
    - 2.2923507895962945
    - 2.4696841650995713
    - 2.7000807482620766
    - 2.793089907744835
    - 2.8735064761392
    - 3.0408891644971123
    - 3.1001355031440996
    - 3.042959353019451
    - 3.289957749432531
    - 3.1368540566543053
    - 2.96348106450048
    - 3.1046857751649
    - 3.183920930171835
    - 3.641264533174449
    - 3.9480741024017334
    - 3.599623754106719
    - 3.836237385355193
    - 3.774613881933278
    - 3.973839985913244
    - 4.048213321587135
    - 3.8428361950249506
    - 3.806807041168213
    - 3.9122116483491043
    - 4.397243717621112
    - 4.493449387879207
    - 3.903864157610926
    - 4.811696253973862
    - 4.295247772644306
    - 4.205205124000023
    - 4.262420300779672
    - 4.04203946425997
    - 3.6754245922483246
    - 3.962023455521156
    - 3.5042018027141175
    - 3.7012957622264993
    - 3.8894089707012833
    - 4.294607109036939
    - 4.258530139923096
    - 4.425097827253671
    - 4.121799682748729
    - 3.814708713827462
    - 3.732675988098671
    - 4.1040543934394575
    - 4.3121300976851895
    - 4.899583487675108
    - 4.439386417125833
    - 4.605059997788791
    - 3.8284657988055
    - 4.394972665556546
    - 4.4723712493633405
    - 4.057706397155235
    - 3.7924539960663894
    - 3.7525518885974227
    - 3.9132262756084573
    - 3.7100835915269523
    - 3.62334930074626
    - 3.793794031800895
    - 3.881630507008783
    - 4.145770882738048
    - 3.60312963765243
    - 3.796833268527327
    - 3.729113192393862
    - 3.8034487798296173
    - 3.89451605698158
    - 4.0266878276035705
    - 3.8208567479561113
    - 3.7566576127348275
    - 3.8115732669830322
    - 3.7930378708346137
    - 3.80292861626066
    - 3.800257181299144
    - 3.791071213524917
    - 3.8212332725524902
    - 3.848417582183049
    - 4.0365489186911745
    - 4.0310460452375745
    - 4.106119501179662
    - 4.055134407405196
    - 4.247185690649625
    - 4.129159676617589
    - 4.3995819543970045
    - 4.163148785459584
    - 3.9034414003635276
    - 3.8507037491633973
    - 3.871163984824871
    - 4.00847012832247
    - 4.061046357812552
  metrics:
    svhn_top1_accuracy:
    - 0.20391522990218525
    - 0.14625538795672613
    - 0.16629849143069367
    - 0.1964080462168003
    - 0.20877334783817159
    - 0.2253322557642542
    - 0.20358297434346428
    - 0.2532147988677025
    - 0.21378412380300718
    - 0.27521551734414595
    - 0.274604885228749
    - 0.2801275145390938
    - 0.2928520117340417
    - 0.32521551744691257
    - 0.3212464081829992
    - 0.31023706906828385
    - 0.32003412370024054
    - 0.3422593392174819
    - 0.33956537370024054
    - 0.34169360635609464
    - 0.39072377876988773
    - 0.3762122844827586
    - 0.36118893685012027
    - 0.3953753596749799
    - 0.40520833381291094
    - 0.4106950431034483
    - 0.368462643746672
    - 0.3535470546319567
    - 0.38641343394230154
    - 0.36970186798736965
    - 0.40877334773540497
    - 0.39955100622670403
    - 0.4038613510542902
    - 0.42113864935677625
    - 0.4048311782294306
    - 0.3987338363096632
    - 0.38533584773540497
    - 0.3948994253216119
    - 0.4243714079774659
    - 0.3807830461140337
    - 0.425035919608741
    - 0.42254849137931033
    - 0.42931932519222127
    - 0.4228448276889735
    - 0.4321749282294306
    - 0.43682650862068967
    - 0.47454202586206895
    - 0.44198096312325574
    - 0.4221803165715316
    - 0.4143678165715316
    - 0.4309716234947073
    - 0.4300915948275862
    - 0.4359823994595429
    - 0.45099676734414595
    - 0.47629310344827586
    - 0.47184806034482757
    - 0.46936063211539697
    - 0.4166576872611868
    - 0.442385057950842
    - 0.4194145115285084
    - 0.477307830391259
    - 0.4398617097016039
    - 0.42689475622670403
    - 0.45033225622670403
    - 0.4809806038593424
    - 0.48548850622670403
    - 0.48814655172413796
    - 0.49414511487401763
    - 0.4871048855370489
    - 0.4872036637931034
    - 0.4808459055834803
    - 0.46454741420416995
    - 0.495186782088773
    - 0.4754489942871291
    - 0.47888829070946265
    - 0.48811961248003205
    - 0.48286637972141133
    - 0.47586206937658376
    - 0.4958333331963112
    - 0.5047234194032078
    - 0.5036458331963112
    - 0.5105783045291901
    - 0.5092313217705694
    - 0.5141433189655172
    - 0.5129669545025661
    - 0.5083512931034483
    - 0.5118893682956696
    - 0.5020563941577385
    - 0.5001706182956696
    - 0.4959949717439454
    - 0.499093032088773
    - 0.4866020114257418
    - 0.4904723424336006
    - 0.48414152346808337
    - 0.49289691139911784
    - 0.5053520115285084
    - 0.5007722701491981
    - 0.5051544545025661
    - 0.5045168821153969
    - 0.49299568965517243
    svhn_top5_accuracy:
    - 0.6253412355636728
    - 0.6217672413793104
    - 0.6258081896551724
    - 0.6197198279972734
    - 0.6152747848938251
    - 0.6584500721816359
    - 0.6390804597016039
    - 0.7040140084151564
    - 0.7008351293103449
    - 0.7330369969894146
    - 0.7370150860013633
    - 0.7502424573076183
    - 0.7369073279972734
    - 0.7763110635609463
    - 0.7795438221816359
    - 0.7709859917903769
    - 0.7653017239323978
    - 0.7721354170092221
    - 0.7876616377255012
    - 0.787491020457498
    - 0.8119791663926224
    - 0.7968570405039294
    - 0.7876257187333601
    - 0.8149425284615879
    - 0.8224497129177225
    - 0.8191810342772253
    - 0.8015355601392943
    - 0.8003232756565357
    - 0.8223509336340016
    - 0.8257183905305534
    - 0.8224497129177225
    - 0.8212733474271051
    - 0.822279094622053
    - 0.8187140801857258
    - 0.8218480605503609
    - 0.8224856319098637
    - 0.8081357756565357
    - 0.8167923853315157
    - 0.8391882181167603
    - 0.8198904456763432
    - 0.8382453301857258
    - 0.8405711208951885
    - 0.8317798129443464
    - 0.8401311060477947
    - 0.8458243536538091
    - 0.8514188219761026
    - 0.8661637933089815
    - 0.8408405174469126
    - 0.8344737784615879
    - 0.8444773708951885
    - 0.8398976295158781
    - 0.8438397985080193
    - 0.8556214077719326
    - 0.862086925013312
    - 0.8648168105503609
    - 0.8607758622744988
    - 0.857040229542502
    - 0.8540409484813953
    - 0.8520204743434643
    - 0.838649425013312
    - 0.8579471984813953
    - 0.8459949709218124
    - 0.8419181036538091
    - 0.8564655174469126
    - 0.8623922415848436
    - 0.8643767957029671
    - 0.8646461922546913
    - 0.8701688215650362
    - 0.8709770112202085
    - 0.8676095543236568
    - 0.855387931240016
    - 0.8455908760942262
    - 0.8631016519562952
    - 0.8620599857692061
    - 0.865086207102085
    - 0.8732040226459503
    - 0.872898707102085
    - 0.8694324709218124
    - 0.8719917381631916
    - 0.8741109915848436
    - 0.8753232760676022
    - 0.8794001433356055
    - 0.8812859191976744
    - 0.878322557128709
    - 0.878322557128709
    - 0.8777478450331194
    - 0.8781519398607057
    - 0.8741109915848436
    - 0.8752244967838814
    - 0.874919181240016
    - 0.8789960485080193
    - 0.8759967674469126
    - 0.8789242094960706
    - 0.8720186784349638
    - 0.8786548129443464
    - 0.8738415950331194
    - 0.874551005404571
    - 0.8756285916114676
    - 0.8740122123011227
    - 0.8789960485080193
