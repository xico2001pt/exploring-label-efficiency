device: cuda
duration: 435.62484407424927
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  num_workers: 4
  save_freq: 30
loss:
  args: {}
  class: CrossEntropyLoss
metrics:
  svhn_top1_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 1
    class: Accuracy
  svhn_top5_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 5
    class: Accuracy
model:
  args:
    num_classes: 10
  class: ResNet50
optimizer:
  args:
    lr: 0.001
  class: Adam
train_dataset:
  args:
    num_labeled: 500
    root: ./data/
    train_val_split: 0.9
  class: FineTuningTrainSVHN
train_history:
  loss:
    total:
    - 2.5420435070991516
    - 2.075467586517334
    - 1.7249346673488617
    - 1.3995706737041473
    - 1.1243184208869934
    - 0.9128213673830032
    - 0.6869344711303711
    - 0.5434287935495377
    - 0.36639709770679474
    - 0.22769809886813164
    - 0.16668644547462463
    - 0.12181250005960464
    - 0.12307902425527573
    - 0.08241751417517662
    - 0.07262842543423176
    - 0.08199801295995712
    - 0.06532209366559982
    - 0.04941595625132322
    - 0.1520867571234703
    - 0.10432519018650055
    - 0.0937823997810483
    - 0.09441004507243633
    - 0.08669431693851948
    - 0.09222658444195986
    - 0.11271094810217619
    - 0.07007101643830538
    - 0.07198511809110641
    - 0.05254055326804519
    - 0.048958828672766685
    - 0.02564188139513135
    - 0.022544247563928366
    - 0.016980555607005954
    - 0.01451229420490563
    - 0.015103045385330915
    - 0.006882806308567524
    - 0.01029884343734011
    - 0.00826617784332484
    - 0.010958362952806056
    - 0.006832957151345909
    - 0.005833144299685955
    - 0.005846743588335812
    - 0.004724193102447316
    - 0.004952739021973684
    - 0.006404465704690665
    - 0.00326022258377634
    - 0.005951418046606705
    - 0.004909908166155219
    - 0.0033049455960281193
    - 0.003399348075618036
    - 0.0015216333558782935
    - 0.004376541008241475
    - 0.0016143155517056584
    - 0.004427193489391357
    - 0.0023168480111053213
    - 0.000607563961239066
    - 0.0025803575990721583
    - 0.004934069758746773
    - 0.011119219416286796
    - 0.024965866323327646
    - 0.007599645876325667
    - 0.01153854769654572
    - 0.007071510481182486
    - 0.018939355039037764
    - 0.022841937723569572
    - 0.02761710132472217
    - 0.02504759281873703
    - 0.026151676196604967
    - 0.04170778626576066
    - 0.04238569550216198
    - 0.08247380168177187
    - 0.09756341949105263
    - 0.0840783454477787
    - 0.1337524000555277
    - 0.11531733442097902
    - 0.14638186804950237
    - 0.17897692508995533
    - 0.17515748739242554
    - 0.14604136161506176
    - 0.11069656908512115
    - 0.13616356998682022
    - 0.07632382307201624
    - 0.06655675638467073
    - 0.028215160127729177
    - 0.024896363029256463
    - 0.05194866401143372
    - 0.03686622949317098
    - 0.0273744179867208
    - 0.029261269373819232
    - 0.015665078535676003
    - 0.019588544266298413
    - 0.007049387262668461
    - 0.008175306604243815
    - 0.008613481128122658
    - 0.009359637508168817
    - 0.003824070270638913
    - 0.003967978933360428
    - 0.0038907559646759182
    - 0.0010824087876244448
    - 0.0034526370582170784
    - 0.018284237652551383
  metrics:
    svhn_top1_accuracy:
    - 0.15288254246115685
    - 0.2646147646009922
    - 0.41729526221752167
    - 0.498046875
    - 0.6344962269067764
    - 0.7097925692796707
    - 0.7687904089689255
    - 0.830549567937851
    - 0.9151400923728943
    - 0.9530576467514038
    - 0.9597252160310745
    - 0.9783135801553726
    - 0.9718480557203293
    - 0.9777074307203293
    - 0.9861260801553726
    - 0.9779094755649567
    - 0.9796605557203293
    - 0.9900323301553726
    - 0.9595231711864471
    - 0.9722521603107452
    - 0.9714439660310745
    - 0.9694908410310745
    - 0.9761584103107452
    - 0.9798626005649567
    - 0.9755522608757019
    - 0.9818157255649567
    - 0.9761584103107452
    - 0.9853178858757019
    - 0.994140625
    - 0.9939385801553726
    - 0.998046875
    - 0.9958917051553726
    - 0.998046875
    - 0.998046875
    - 1.0
    - 0.99609375
    - 1.0
    - 0.998046875
    - 0.998046875
    - 0.9978448301553726
    - 1.0
    - 1.0
    - 0.998046875
    - 0.9978448301553726
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9978448301553726
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 1.0
    - 0.998046875
    - 0.998046875
    - 0.9937365353107452
    - 0.9978448301553726
    - 0.998046875
    - 0.99609375
    - 0.9939385801553726
    - 0.9937365353107452
    - 0.9917834103107452
    - 0.9919854551553726
    - 0.9880792051553726
    - 0.9837688505649567
    - 0.9861260801553726
    - 0.9753502160310745
    - 0.9638335108757019
    - 0.9763604551553726
    - 0.9554148763418198
    - 0.9677397608757019
    - 0.9601293057203293
    - 0.9341325461864471
    - 0.9478044211864471
    - 0.9491513967514038
    - 0.9620824307203293
    - 0.9698949307203293
    - 0.9740032255649567
    - 0.9753502160310745
    - 0.9900323301553726
    - 0.998046875
    - 0.9833647608757019
    - 0.9896282255649567
    - 0.9900323301553726
    - 0.9939385801553726
    - 0.9958917051553726
    - 0.9937365353107452
    - 0.998046875
    - 1.0
    - 0.998046875
    - 0.9958917051553726
    - 1.0
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 0.9958917051553726
    svhn_top5_accuracy:
    - 0.5704471915960312
    - 0.7345770448446274
    - 0.8397090584039688
    - 0.9163523763418198
    - 0.9603313505649567
    - 0.9620824307203293
    - 0.9878771603107452
    - 0.994140625
    - 0.9978448301553726
    - 0.998046875
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.998046875
    - 0.9978448301553726
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.998046875
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
val_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: LinearEvalSVHN
validation_history:
  loss:
    total:
    - 2.3338256211116395
    - 2.170438587665558
    - 2.558536591200993
    - 2.333850398145873
    - 2.526357346567614
    - 2.55645096713099
    - 2.395638640584617
    - 2.126268740358024
    - 2.2839881798316695
    - 2.0515150879991464
    - 2.227835515449787
    - 2.30077830059775
    - 2.436060262137446
    - 3.146993719298264
    - 3.813387184307493
    - 3.2519327361008217
    - 2.833974069562452
    - 3.0848581790924072
    - 3.241820113412265
    - 2.8192716138116243
    - 2.8653586506843567
    - 2.89431998236426
    - 3.332092231717603
    - 3.0371852948747833
    - 3.5288729708770226
    - 4.15316471560248
    - 3.3626156223231347
    - 3.4815970885342566
    - 3.241594028883967
    - 2.7615970311493707
    - 2.4178584094705253
    - 2.2146843240178864
    - 2.2909350045796097
    - 2.372904960451455
    - 2.5106057935747605
    - 2.7338633907252343
    - 2.8600337423127273
    - 2.724553136989988
    - 2.7583301396205506
    - 2.659174279919986
    - 2.668909890898343
    - 2.649503103617964
    - 2.540021830591662
    - 2.5074400655154525
    - 2.5821567568285713
    - 2.6773297396199456
    - 2.6650692018969306
    - 2.661038339138031
    - 2.6974054451646476
    - 2.7719328197939643
    - 2.839057885367295
    - 3.0723370231431106
    - 2.913862417484152
    - 2.83851446365488
    - 2.806724431185887
    - 2.8260143111492027
    - 2.990588239554701
    - 2.620355180625258
    - 2.6690388630176414
    - 2.7815015727076036
    - 2.843475615156108
    - 3.0501574730050973
    - 3.185562516080922
    - 3.5654680441165794
    - 3.1035879398214408
    - 3.00463140216367
    - 3.5552634987337837
    - 3.887133676430275
    - 3.522398023769773
    - 3.59056123371782
    - 5.635924035105212
    - 7.032137517271371
    - 4.890103414140898
    - 3.8124314875438294
    - 4.094859032795347
    - 3.6915303448150896
    - 3.0175280735410492
    - 3.9973959635043967
    - 5.92917329689552
    - 3.576296909102078
    - 2.7919119966441186
    - 2.4964819427194267
    - 2.485053681094071
    - 2.6926305622890077
    - 2.258178934968751
    - 2.1404875599104782
    - 2.232206915986949
    - 2.3679012389018617
    - 2.514453912603444
    - 2.5501843464785607
    - 2.7150272829779265
    - 2.721215083681304
    - 2.5037672478577186
    - 2.2656910542784066
    - 2.2677409093955467
    - 2.2305674635130783
    - 2.147971364958533
    - 2.2278515162139105
    - 2.2692509869049333
    - 2.223259146871238
  metrics:
    svhn_top1_accuracy:
    - 0.1897090519296712
    - 0.2540229885228749
    - 0.3095635776889735
    - 0.34576149438989573
    - 0.33933189665449076
    - 0.34926364956230954
    - 0.399712643746672
    - 0.4345635776889735
    - 0.4195132902983961
    - 0.4421695404011628
    - 0.4695132904011628
    - 0.4847431753216119
    - 0.4990571120689655
    - 0.4598239942871291
    - 0.43075610645886125
    - 0.45274784493035286
    - 0.4958333331963112
    - 0.4841684627121893
    - 0.4736619971949479
    - 0.4956267959085004
    - 0.525026940066239
    - 0.5293732038859663
    - 0.5017869976060144
    - 0.5230423849204491
    - 0.488918821873336
    - 0.458198635228749
    - 0.5092941810344828
    - 0.5006824711273457
    - 0.5193336924602245
    - 0.5378142960112671
    - 0.569647988368725
    - 0.5862517963195669
    - 0.5783405170358461
    - 0.5828843394230152
    - 0.5724766521618284
    - 0.5698186066643945
    - 0.5711027301591018
    - 0.5779992814721733
    - 0.5742636497678428
    - 0.5801903739057738
    - 0.5824443245756215
    - 0.5862158762997595
    - 0.5878951148740177
    - 0.5874999997944668
    - 0.5821479887797915
    - 0.5698904456763432
    - 0.5704920980437048
    - 0.5753053159549318
    - 0.5761135056101042
    - 0.570761494595429
    - 0.5686063221816359
    - 0.5525772273540497
    - 0.5653376435411388
    - 0.5740211924602245
    - 0.5805226297214113
    - 0.5799209773540497
    - 0.5660111349204491
    - 0.5795797417903769
    - 0.579714440066239
    - 0.5843570407094627
    - 0.5790409486869286
    - 0.5680316090583801
    - 0.5737248566643945
    - 0.5521731325264635
    - 0.5675915952386528
    - 0.5611619969894146
    - 0.5576957618368084
    - 0.5341145838129109
    - 0.5329651580802326
    - 0.5316540948275862
    - 0.46271551734414595
    - 0.361287715620008
    - 0.4262482040914996
    - 0.4702945402983961
    - 0.46735811798736965
    - 0.47006106325264635
    - 0.5609913797214113
    - 0.5418642245489975
    - 0.48107938211539697
    - 0.5533854170092221
    - 0.5763110631498797
    - 0.5921066814455492
    - 0.5915050290781876
    - 0.5793462642307939
    - 0.6253502153117081
    - 0.6452137211273457
    - 0.627631106253328
    - 0.6200610635609463
    - 0.6224856325264635
    - 0.6299928159549318
    - 0.6155441814455492
    - 0.6166217676524458
    - 0.6331896555834803
    - 0.644001436644587
    - 0.6424209773540497
    - 0.6540409480703289
    - 0.6674119974004811
    - 0.6631645118368084
    - 0.6634339083885324
    - 0.6657237790781876
    svhn_top5_accuracy:
    - 0.6645833336073776
    - 0.7106501439522053
    - 0.7343570405039294
    - 0.7538882905039294
    - 0.7541576870556536
    - 0.8000538791048115
    - 0.8298940370822775
    - 0.8423581174735365
    - 0.8470994974004811
    - 0.8594647985080193
    - 0.8682561064588612
    - 0.8646821122744988
    - 0.8715517243434643
    - 0.8644127157227747
    - 0.8574443243700882
    - 0.8669091237002405
    - 0.8737068967572574
    - 0.8761673847149158
    - 0.8688936778183641
    - 0.8763739220027266
    - 0.8845905168303128
    - 0.8847611351259823
    - 0.8838182471949478
    - 0.8909572558156376
    - 0.8765086202785887
    - 0.8733746409416199
    - 0.8841505030105854
    - 0.8737428157493986
    - 0.8775862064854852
    - 0.8867456892441059
    - 0.8988685340716921
    - 0.9062769392441059
    - 0.9043193243700882
    - 0.9065104168036888
    - 0.9035829737268645
    - 0.900853089217482
    - 0.8992367099071371
    - 0.903618893746672
    - 0.9033494971949478
    - 0.9046964799535686
    - 0.9045617816777065
    - 0.9076239220027266
    - 0.9096803161604651
    - 0.9121048851259823
    - 0.9102191092639134
    - 0.9072198271751404
    - 0.9057381461406576
    - 0.9053340513130714
    - 0.9030441806234163
    - 0.9034123564588612
    - 0.9038164512864475
    - 0.9050287357692061
    - 0.9057022271485164
    - 0.904525861657899
    - 0.9050646547613472
    - 0.9061422409682438
    - 0.9049299564854852
    - 0.9042923851259823
    - 0.9041576868501203
    - 0.904391163382037
    - 0.9002514368501203
    - 0.8993085489190858
    - 0.9003861351259823
    - 0.8885686058422615
    - 0.8944594109880513
    - 0.9018318961406576
    - 0.9003502151061749
    - 0.8951329023673616
    - 0.8906160202519647
    - 0.895195761631275
    - 0.8821659478647955
    - 0.8019127157227747
    - 0.8292205457029671
    - 0.8496318243700882
    - 0.8623563215650362
    - 0.8882273702785887
    - 0.8897808903250201
    - 0.8844558185544508
    - 0.8857040230570168
    - 0.9005477726459503
    - 0.9091684623011227
    - 0.9173221978647955
    - 0.9223778730836408
    - 0.9187410196353649
    - 0.9213002868767443
    - 0.9204920972215718
    - 0.9182022265319166
    - 0.9166846265052927
    - 0.9114942530105854
    - 0.914224137519968
    - 0.914592313355413
    - 0.914727011631275
    - 0.9167474857692061
    - 0.9185704023673616
    - 0.9170887213328789
    - 0.9185704023673616
    - 0.9205908765052927
    - 0.9204561782294306
    - 0.9207255747811548
    - 0.9251706178846031
