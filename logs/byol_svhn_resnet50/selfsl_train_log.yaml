device: cuda
duration: 20980.281132936478
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  max_num_samples: -1
  num_workers: 4
  save_freq: 30
method:
  args:
    color_jitter_strength: 1
    ema_decay: 0.99
    hidden_size: 2048
    image_size: 224
    prediction_size: 128
    projection_size: 128
    representation_size: 128
  class: BYOLSVHN
metrics: {}
model:
  args:
    num_classes: 10
  class: ResNet50
optimizer:
  args:
    lr: 0.0003
  class: Adam
train_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: UnsupervisedSVHN
train_history:
  loss:
    total:
    - 0.7004865403748253
    - 0.28629485371622065
    - 0.19828974343655467
    - 0.24206928196317942
    - 0.17879494246348593
    - 0.16962265158162534
    - 0.45104189296659913
    - 0.31197301527684174
    - 0.261924430706258
    - 0.2315035139834418
    - 0.23899291687943403
    - 0.2268390313224885
    - 0.19904260018352166
    - 0.1950067298432577
    - 0.2153152579568254
    - 0.17347230768753488
    - 0.1903609975123579
    - 0.17288174995591918
    - 0.17195564153812173
    - 0.1617748555175743
    - 0.24893427264415524
    - 0.23348950140756888
    - 0.18929510236654468
    - 0.15960826043545912
    - 0.15995379609137195
    - 0.1661939110860084
    - 0.16571813145091813
    - 0.1522720234558999
    - 0.16525370335405312
    - 0.16009649683549565
    - 0.14487006965554455
    - 0.1413086263770328
    - 0.15381952462699808
    - 0.14193382320147985
    - 0.14571406805471887
    - 0.15362749202990705
    - 0.1493780174012323
    - 0.14946943960939219
    - 0.14154875560943941
    - 0.13293917975162417
    - 0.13985918074556924
    - 0.14280604745794848
    - 0.14170983536259352
    - 0.14772076734784736
    - 0.14065005255193966
    - 0.1291602561738595
    - 0.14195912301142527
    - 0.1277518481088495
    - 0.13491862863302231
    - 0.1338057062109408
    - 0.14524532749308544
    - 0.13796024531379197
    - 0.13292395995875586
    - 0.14118523953247417
    - 0.14255532565915469
    - 0.13002485002128825
    - 0.1401994728636973
    - 0.13139118408259837
    - 0.1407892974473319
    - 0.1358881697745867
    - 0.12119168597228319
    - 0.1264938516451896
    - 0.13118710418421667
    - 0.12754326239228247
    - 0.12555592985263148
    - 0.11784338233540359
    - 0.13325918104897425
    - 0.12716358172372708
    - 0.1435508511490324
    - 0.12337914728785603
    - 0.11448326024398642
    - 0.1204603837025397
    - 0.12475588637792949
    - 0.12003462869059113
    - 0.11750938278957478
    - 0.10843525186759755
    - 0.11648059675777421
    - 0.11646074559720396
    - 0.1130768203149432
    - 0.12208063627765017
    - 0.12155731742460173
    - 0.11401560728989758
    - 0.1115125294991778
    - 0.1157982712087122
    - 0.1105298974668806
    - 0.1070924434232191
    - 0.10101184595412421
    - 0.11450563994715515
    - 0.1071554338939271
    - 0.10811096171586258
    - 0.11081916498544725
    - 0.11011232623052829
    - 0.11343129692798101
    - 0.1088978785768296
    - 0.10752183215566052
    - 0.11118860410038128
    - 0.11392308907963118
    - 0.11221619954025283
    - 0.10631858051835912
    - 0.10548943800182597
  metrics: {}
