device: cuda
duration: 72281.96738290787
hyperparameters:
  batch_size: 64
  ema_decay: null
  epochs: 100
  max_num_samples: -1
  num_workers: 4
  save_freq: 30
method:
  args:
    color_jitter_strength: 1
    ema_decay: 0.99
    hidden_size: 2048
    image_size: 224
    prediction_size: 128
    projection_size: 128
    representation_size: 128
  class: BYOLSVHN
metrics: {}
model:
  args:
    depth: 28
    num_classes: 10
    width: 2
  class: WideResNet
optimizer:
  args:
    lr: 0.0003
  class: Adam
train_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: UnsupervisedSVHN
train_history:
  loss:
    total:
    - 0.5337941773235798
    - 0.2615067226396313
    - 0.22094404925275773
    - 0.22290452108582826
    - 0.19936884517410716
    - 0.19034252162407903
    - 0.22722128315024007
    - 0.18215883580913533
    - 0.19244922827205901
    - 0.19372661300907726
    - 0.18750494923080924
    - 0.1825203555608982
    - 0.18406587512892428
    - 0.19202464462520138
    - 0.18152416958428413
    - 0.17219373900985835
    - 0.17391633202041526
    - 0.17711062992299065
    - 0.17893365253558727
    - 0.16915062533926617
    - 0.17604793139995592
    - 0.17418131135331774
    - 0.17022607924904928
    - 0.16999397640053218
    - 0.16785176679745173
    - 0.15990887706538717
    - 0.16697604461817198
    - 0.16506213562074795
    - 0.1656420153285404
    - 0.16325791393705075
    - 0.1568017482088463
    - 0.1685914658498272
    - 0.16314675932912862
    - 0.16397792657529844
    - 0.16158711142584825
    - 0.1635198859425569
    - 0.16233324775815877
    - 0.15682440548954368
    - 0.15919296651970125
    - 0.1533538308012688
    - 0.160561335824647
    - 0.15788690096255645
    - 0.16394974203979218
    - 0.15605628200020027
    - 0.1535796146857941
    - 0.1545111022347096
    - 0.1519527394631968
    - 0.15309377805085725
    - 0.1560461171387324
    - 0.15799359926791157
    - 0.1501643951349322
    - 0.1571599865314162
    - 0.15569970400154012
    - 0.15535779199698596
    - 0.1582997318429565
    - 0.15205522174901753
    - 0.14944657968917807
    - 0.15190690311341032
    - 0.14395670941262279
    - 0.1530752037100277
    - 0.15158551254499594
    - 0.1498699423070382
    - 0.15388525446099274
    - 0.1497513279119886
    - 0.15756726628440676
    - 0.1518099277578656
    - 0.1559880543011919
    - 0.16733567827534906
    - 0.16814259068986165
    - 0.1596455162228311
    - 0.16010678632962472
    - 0.15542671665440774
    - 0.14843166697300175
    - 0.14692198818603766
    - 0.16014659890850771
    - 0.14844535830096134
    - 0.15688865090024123
    - 0.15099572208031867
    - 0.14781850173490718
    - 0.15512869371444854
    - 0.1528897202745514
    - 0.14267255018637018
    - 0.14208205611381716
    - 0.14629343710839748
    - 0.14291004235811025
    - 0.14429265042242495
    - 0.14796273860248546
    - 0.14776236583451624
    - 0.14723594159032535
    - 0.1398742855752556
    - 0.1441049512222554
    - 0.14052019613315758
    - 0.14536688886221172
    - 0.145574820338233
    - 0.1438705436089664
    - 0.14532680317614843
    - 0.14670740586606043
    - 0.1397573845985445
    - 0.1399920010233967
    - 0.14672795366315008
  metrics: {}
