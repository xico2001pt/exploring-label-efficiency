device: cuda
duration: 1998.2782089710236
hyperparameters:
  batch_size: 128
  ema_decay: null
  epochs: 100
  num_workers: 4
  save_freq: 30
loss:
  args: {}
  class: CrossEntropyLoss
metrics:
  svhn_top1_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 1
    class: Accuracy
  svhn_top5_accuracy:
    args:
      num_classes: 10
      task: multiclass
      top_k: 5
    class: Accuracy
model:
  args:
    num_classes: 10
  class: ResNet50
optimizer:
  args:
    lr: 0.001
  class: Adam
train_dataset:
  args:
    num_labeled: 1000
    root: ./data/
    train_val_split: 0.9
  class: FineTuningTrainSVHN
train_history:
  loss:
    total:
    - 2.3559111654758453
    - 2.2450232803821564
    - 2.1647764146327972
    - 2.0383821427822113
    - 1.9435910284519196
    - 1.832176223397255
    - 1.6509013026952744
    - 1.536355897784233
    - 1.4157613515853882
    - 1.2345768958330154
    - 1.0913578048348427
    - 0.991832934319973
    - 0.8563787192106247
    - 0.7717366069555283
    - 0.6318580135703087
    - 0.6053794398903847
    - 0.5301283858716488
    - 0.4158393405377865
    - 0.4075968824326992
    - 0.35357481241226196
    - 0.32598365284502506
    - 0.31801997497677803
    - 0.27031288482248783
    - 0.19770225510001183
    - 0.15754962246865034
    - 0.1710679568350315
    - 0.11572148278355598
    - 0.09934030706062913
    - 0.09737210883758962
    - 0.08855684427544475
    - 0.1175508457235992
    - 0.10950173670426011
    - 0.10994129907339811
    - 0.11672319052740932
    - 0.14984286297112703
    - 0.10794904222711921
    - 0.09563125763088465
    - 0.12536165677011013
    - 0.1252786135300994
    - 0.07945911679416895
    - 0.06749608553946018
    - 0.060239481972530484
    - 0.049648176645860076
    - 0.05805139243602753
    - 0.054677502484992146
    - 0.04612323991023004
    - 0.037359598092734814
    - 0.05913649406284094
    - 0.03319646907038987
    - 0.037010631640441716
    - 0.0308039803057909
    - 0.03517808683682233
    - 0.021408543863799423
    - 0.025087829562835395
    - 0.025864816387183964
    - 0.023130572750233114
    - 0.030524653266184032
    - 0.025979331840062514
    - 0.024001445330213755
    - 0.019800079404376447
    - 0.023766689002513885
    - 0.028293970972299576
    - 0.026395008200779557
    - 0.025729003769811243
    - 0.023836078005842865
    - 0.05260788695886731
    - 0.10004906391259283
    - 0.1060606399551034
    - 0.08121776068583131
    - 0.05920777563005686
    - 0.05978185124695301
    - 0.06849881797097623
    - 0.031340842600911856
    - 0.043278303113766015
    - 0.03817844740115106
    - 0.037547294166870415
    - 0.0509559198981151
    - 0.04326907603535801
    - 0.05156494246330112
    - 0.051275148056447506
    - 0.03247043222654611
    - 0.06054600537754595
    - 0.03348101698793471
    - 0.02403840352781117
    - 0.032968394400086254
    - 0.030968268227297813
    - 0.02231679775286466
    - 0.01307927438756451
    - 0.026045276987133548
    - 0.03177480878366623
    - 0.039448136813007295
    - 0.030442522809607908
    - 0.021825727686518803
    - 0.015549722709693015
    - 0.006840278845629655
    - 0.015150682971579954
    - 0.012746721084113233
    - 0.023064816821715795
    - 0.007825433800462633
    - 0.019005179885425605
  metrics:
    svhn_top1_accuracy:
    - 0.15955528803169727
    - 0.20327524095773697
    - 0.2509765625
    - 0.27373798191547394
    - 0.32256610691547394
    - 0.3505108170211315
    - 0.4242037273943424
    - 0.4813701957464218
    - 0.5268179103732109
    - 0.582181490957737
    - 0.6227463930845261
    - 0.6527944728732109
    - 0.6959134638309479
    - 0.7397836521267891
    - 0.7772686332464218
    - 0.796724759042263
    - 0.8226412236690521
    - 0.8588491603732109
    - 0.8636568486690521
    - 0.8734224736690521
    - 0.8971604555845261
    - 0.8947566077113152
    - 0.9082782417535782
    - 0.9381009638309479
    - 0.951998196542263
    - 0.9465895444154739
    - 0.9688251167535782
    - 0.9670973569154739
    - 0.9678485542535782
    - 0.971529446542263
    - 0.9661207944154739
    - 0.9631911069154739
    - 0.9688251167535782
    - 0.9593599736690521
    - 0.9525240361690521
    - 0.965670071542263
    - 0.9629657417535782
    - 0.9571063667535782
    - 0.9622145444154739
    - 0.9739332944154739
    - 0.9751352146267891
    - 0.9795673042535782
    - 0.9831730797886848
    - 0.9810697138309479
    - 0.9790414646267891
    - 0.9888070896267891
    - 0.9890324547886848
    - 0.9834735542535782
    - 0.9919621422886848
    - 0.9892578125
    - 0.9870793297886848
    - 0.98828125
    - 0.9931640625
    - 0.994140625
    - 0.9931640625
    - 0.994140625
    - 0.9909855797886848
    - 0.9909855797886848
    - 0.9921875
    - 0.9931640625
    - 0.9921875
    - 0.9929387047886848
    - 0.9921875
    - 0.9921875
    - 0.9927133396267891
    - 0.9834735542535782
    - 0.972506009042263
    - 0.9653695896267891
    - 0.9758864194154739
    - 0.9773137047886848
    - 0.9776141792535782
    - 0.9797926694154739
    - 0.990234375
    - 0.9856520444154739
    - 0.9880558922886848
    - 0.9888070896267891
    - 0.9907602146267891
    - 0.9864032417535782
    - 0.9824969917535782
    - 0.9785907417535782
    - 0.9870793297886848
    - 0.9817457944154739
    - 0.9888070896267891
    - 0.9921875
    - 0.9909855797886848
    - 0.9897836521267891
    - 0.9900090172886848
    - 0.9954176694154739
    - 0.9897836521267891
    - 0.9870793297886848
    - 0.9888070896267891
    - 0.9912109375
    - 0.9948918297886848
    - 0.9958683922886848
    - 0.9990234375
    - 0.9939152672886848
    - 0.9958683922886848
    - 0.9921875
    - 1.0
    - 0.9917367771267891
    svhn_top5_accuracy:
    - 0.609224759042263
    - 0.638521634042263
    - 0.7134915888309479
    - 0.758939303457737
    - 0.7780198305845261
    - 0.8401442319154739
    - 0.874849759042263
    - 0.8881460353732109
    - 0.9036959111690521
    - 0.9413311332464218
    - 0.958834134042263
    - 0.9619891792535782
    - 0.9743840172886848
    - 0.9824969917535782
    - 0.994140625
    - 0.9917367771267891
    - 0.9900090172886848
    - 0.9958683922886848
    - 0.9970703125
    - 0.9990234375
    - 0.9990234375
    - 0.99609375
    - 0.9970703125
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 0.9978215172886848
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9987980797886848
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 0.9990234375
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    - 1.0
val_dataset:
  args:
    root: ./data/
    train_val_split: 0.9
  class: LinearEvalSVHN
validation_history:
  loss:
    total:
    - 2.28980461482344
    - 2.272880221235341
    - 2.1957809637332786
    - 2.097135771965158
    - 2.127597586861972
    - 1.9426035326102684
    - 1.960394170777551
    - 2.087358604217398
    - 1.8704094557926572
    - 1.7078394828171566
    - 1.734971060835082
    - 1.6033087866059665
    - 1.633890421226107
    - 1.836545935992537
    - 2.0757907464586456
    - 1.6371346753219078
    - 1.7558926446684475
    - 1.8009977464018196
    - 1.8827748606944907
    - 2.0166637198678377
    - 1.6177881031200803
    - 1.6660868628271694
    - 1.6919614210210998
    - 1.8767910661368534
    - 1.6367432362046734
    - 1.580612031550243
    - 1.8587372097475776
    - 1.8945369083305885
    - 1.8663499581402745
    - 2.157351216365551
    - 2.360017673722629
    - 2.3271391371200822
    - 2.319140179403897
    - 1.8472285681757434
    - 1.7476643272515
    - 1.891122579574585
    - 2.089337764115169
    - 1.9872067077406521
    - 2.087970090323481
    - 2.0755718720370324
    - 2.154253867165796
    - 1.9137720671193352
    - 1.9234169022790317
    - 1.931061463109378
    - 1.7468142458077134
    - 1.8177143993048832
    - 1.891556711032473
    - 2.2731132281237634
    - 2.155317884067009
    - 2.02121122746632
    - 2.017161821496898
    - 2.0776246148964455
    - 2.0891233723739098
    - 2.178016054219213
    - 1.992345289937381
    - 1.937436615598613
    - 1.940843208082791
    - 2.1108606950990083
    - 2.165147947854009
    - 2.1452846794292846
    - 2.1882997854002593
    - 2.3836111138606895
    - 2.2199316415293464
    - 2.248217360726718
    - 2.2996519516254295
    - 2.167356454092881
    - 2.519597312499737
    - 2.3696243639650016
    - 2.3982948311443986
    - 2.261979522376225
    - 2.204217411320785
    - 2.2914139936710227
    - 2.7192333607838073
    - 2.3029540078393342
    - 2.1747870013631623
    - 1.9500281934080452
    - 1.9843398106509242
    - 2.200402835319782
    - 2.2824093781668564
    - 2.272422642543398
    - 2.387979951398126
    - 1.803128300041988
    - 2.0247956966531686
    - 2.1467746650350503
    - 2.1787213559808403
    - 2.555577857740994
    - 1.974210247911256
    - 1.9632704401838368
    - 2.0457797790395804
    - 2.0218642600651444
    - 2.0793690845884125
    - 1.9961295847235054
    - 1.9797206253841007
    - 1.9382352993406098
    - 2.0094437804715386
    - 1.968045608750705
    - 1.9088482301810692
    - 2.0375634904565483
    - 2.134986367718927
    - 2.012469735638849
  metrics:
    svhn_top1_accuracy:
    - 0.20660919541942663
    - 0.2344917385228749
    - 0.23271372143564553
    - 0.2781429599071371
    - 0.27712823296415395
    - 0.32532327596483557
    - 0.32815193975793905
    - 0.3524245691710505
    - 0.39251077586206895
    - 0.4331896551724138
    - 0.45372665236736165
    - 0.49286099137931033
    - 0.5226652303646351
    - 0.47932830452919006
    - 0.49556393664458703
    - 0.5657776583885324
    - 0.5719378590583801
    - 0.560452586617963
    - 0.5820043107558941
    - 0.5781070405039294
    - 0.615247844622053
    - 0.6338002876988773
    - 0.6330549573076183
    - 0.6160560342772253
    - 0.670070042897915
    - 0.6834051722082598
    - 0.6503681756299118
    - 0.6618893680901363
    - 0.653538074986688
    - 0.6394665950331194
    - 0.6256196118634323
    - 0.6509159484813953
    - 0.6120779452652767
    - 0.687948994595429
    - 0.6709770118368084
    - 0.6769127157227747
    - 0.6567349135875702
    - 0.680881824986688
    - 0.6525592670358461
    - 0.6755657329641539
    - 0.6647180318832397
    - 0.6827586211007217
    - 0.6741469111935846
    - 0.6858656611935846
    - 0.7080908767108259
    - 0.686673850848757
    - 0.6931034480703289
    - 0.6704471984813953
    - 0.6846892957029671
    - 0.6970456180901363
    - 0.6849227732625501
    - 0.6931752870822775
    - 0.696506824986688
    - 0.6831357756565357
    - 0.6991648704841219
    - 0.7122665232625501
    - 0.7123383622744988
    - 0.6970815370822775
    - 0.6814565370822775
    - 0.6954022985080193
    - 0.6892331180901363
    - 0.6835398704841219
    - 0.678116020457498
    - 0.6854256463461909
    - 0.684788074986688
    - 0.694782686644587
    - 0.6679238502321572
    - 0.6688936784349638
    - 0.6662266521618284
    - 0.6855962646418604
    - 0.6663344111935846
    - 0.6753591956763432
    - 0.6635416663926224
    - 0.6813218388064154
    - 0.7007183905305534
    - 0.7125448995623095
    - 0.7062769398607057
    - 0.6943875715650362
    - 0.6866109915848436
    - 0.7013918819098637
    - 0.676975574986688
    - 0.724461207102085
    - 0.7030801002321572
    - 0.6917923853315157
    - 0.6969468388064154
    - 0.6825700433089815
    - 0.7258081898607057
    - 0.7185344829641539
    - 0.724461207102085
    - 0.7127065370822775
    - 0.7107579019562952
    - 0.7244971260942262
    - 0.7184357036804331
    - 0.7181303881365677
    - 0.7188397985080193
    - 0.7308638650795509
    - 0.7349407323475542
    - 0.7257094105769848
    - 0.7077227008753809
    - 0.726481681240016
    svhn_top5_accuracy:
    - 0.6132273704841219
    - 0.6278645838129109
    - 0.6633710491246191
    - 0.7116918101392943
    - 0.7207884336340016
    - 0.7747575435145148
    - 0.7997934623011227
    - 0.7877604170092221
    - 0.8284841950597435
    - 0.8631734909682438
    - 0.8773796691976744
    - 0.8945581892441059
    - 0.8994073271751404
    - 0.900853089217482
    - 0.878457255404571
    - 0.9082255743700882
    - 0.9083961926657578
    - 0.9181663075397755
    - 0.9174928161604651
    - 0.9117007902983961
    - 0.9153017237268645
    - 0.9288793103448276
    - 0.9298850575397755
    - 0.910317887519968
    - 0.9346982754510025
    - 0.9385416661870891
    - 0.9329202586206896
    - 0.9360183189655172
    - 0.9295168817043304
    - 0.9281698989457098
    - 0.9275951868501203
    - 0.9319414506698477
    - 0.9258800282560545
    - 0.9376975575397755
    - 0.9366199713328789
    - 0.9312320402983961
    - 0.9303879306234163
    - 0.9373653017241379
    - 0.9329471978647955
    - 0.9386404454708099
    - 0.9397539506698477
    - 0.9375987782560545
    - 0.935003592022534
    - 0.9391792385742582
    - 0.944198993773296
    - 0.9411637926923817
    - 0.9448365661604651
    - 0.9396192523939856
    - 0.9418103448275862
    - 0.9457794540914995
    - 0.9379669540914995
    - 0.9475305316777065
    - 0.9415050282560545
    - 0.9405980603448276
    - 0.9436602006698477
    - 0.9419091230836408
    - 0.9452406609880513
    - 0.9402568247811548
    - 0.9365840513130714
    - 0.9439295972215718
    - 0.9417744248077787
    - 0.9380028730836408
    - 0.9358117816777065
    - 0.9408315368767443
    - 0.9400233472215718
    - 0.9407327586206896
    - 0.9328843386008822
    - 0.9355783041181236
    - 0.9296156609880513
    - 0.9408943961406576
    - 0.936009339217482
    - 0.9404274420491581
    - 0.9414691092639134
    - 0.9429867092905373
    - 0.9436242816777065
    - 0.9440283765052927
    - 0.9459141523673616
    - 0.9422772989190858
    - 0.9430854885742582
    - 0.9475664506698477
    - 0.9477011489457098
    - 0.948473419608741
    - 0.9404903013130714
    - 0.9454112782560545
    - 0.9424838362068966
    - 0.9428520110146753
    - 0.9488775144363272
    - 0.9429867092905373
    - 0.9493175282560545
    - 0.9486799568965517
    - 0.9470635775862069
    - 0.9436602006698477
    - 0.9450071834284683
    - 0.946722342022534
    - 0.946722342022534
    - 0.950125717911227
    - 0.952011493773296
    - 0.948105243773296
    - 0.9438936782294306
    - 0.9532596982758621
