name: temporal_svhn_wideresnet28_2  # Name of experiment (used for log folder and model naming). If null, the name is the current date and time

model: svhn_wideresnet28_2  # Name of model

semisl_train:
  train_dataset: semi_supervised_svhn_1000l  # Dataset to use for training
  val_dataset: svhn  # Dataset to use for validation
  optimizer: temporal_adam_svhn  # Optimizer
  method: temporal_ensembling_svhn  # Semi-supervised method
  val_loss: cross_entropy  # Loss function
  metrics: [svhn_top1_accuracy, svhn_top5_accuracy]  # Metrics to evaluate
  scheduler: temporal_exp_warmup_lr  # Learning rate scheduler. Can be null
  stop_condition: null  # Condition to stop training. Can be null
  hyperparameters:  # Hyperparameters for training
    epochs: 1024  # Number of training epochs
    num_workers: 4  # Number of workers for data loading
    labeled_batch_size: 64  # Training labeled batch size
    unlabeled_batch_size: 64  # Training unlabeled batch size
    save_freq: 30  # Save model every save_freq epochs. If 0, only the best model is saved
    ema_decay: 0.999  # Exponential moving average decay

test:
  test_dataset: svhn  # Dataset to use for testing
  model_weights_path: temporal_svhn_wideresnet28_2.pth  # Path to model weights (relative to weights folder). If null, config name is used
  loss: cross_entropy  # Loss function
  metrics: [svhn_top1_accuracy, svhn_top5_accuracy]  # Metrics to evaluate
  hyperparameters:  # Hyperparameters for testing
    num_workers: 4  # Number of workers for data loading
    batch_size: 128  # Test batch size
    ema_decay: True  # EMA was used during training
