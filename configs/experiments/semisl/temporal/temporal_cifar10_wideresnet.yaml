name: temporal_cifar10_wideresnet28_2  # Name of experiment (used for log folder and model naming). If null, the name is the current date and time

model: cifar10_wideresnet28_2  # Name of model

semisl_train:
  train_dataset: semi_supervised_cifar10  # Dataset to use for training
  val_dataset: cifar10  # Dataset to use for validation
  optimizer: temporal_adam_cifar10  # Optimizer
  method: temporal_ensembling_cifar10  # Semi-supervised method
  val_loss: cross_entropy  # Loss function
  metrics: [cifar10_top1_accuracy, cifar10_top5_accuracy]  # Metrics to evaluate
  scheduler: pi_model_exp_warmup_lr  # Learning rate scheduler. Can be null
  stop_condition: null  # Condition to stop training. Can be null
  hyperparameters:  # Hyperparameters for training
    epochs: 200  # Number of training epochs
    num_workers: 4  # Number of workers for data loading
    labeled_batch_size: 10  # Training labeled batch size
    unlabeled_batch_size: 102  # Training unlabeled batch size
    save_freq: 30  # Save model every save_freq epochs. If 0, only the best model is saved

test:
  test_dataset: cifar10  # Dataset to use for testing
  model_weights_path: temporal_cifar10_wideresnet28_2.pth  # Path to model weights (relative to weights folder). If null, config name is used
  loss: cross_entropy  # Loss function
  metrics: [cifar10_top1_accuracy, cifar10_top5_accuracy]  # Metrics to evaluate
  hyperparameters:  # Hyperparameters for testing
    num_workers: 4  # Number of workers for data loading
    batch_size: 128  # Test batch size
