name: byol_eval_kitti_mobilenet_18l  # Name of experiment (used for log folder and model naming). If null, the name is the current date and time

model: kitti_deeplabv3_mobilenet  # Name of model

sl_train:
  train_dataset: fine_tuning_kitti_segmentation_18l  # Dataset to use for training
  val_dataset: linear_eval_kitti  # Dataset to use for validation
  optimizer: byol_kitti_adam  # Optimizer
  loss: kitti_cross_entropy  # Loss function
  metrics: [kitti_jaccard_macro, kitti_jaccard_micro, kitti_dice]  # Metrics to evaluate
  scheduler: null  # Learning rate scheduler. Can be null
  stop_condition: null  # Condition to stop training. Can be null
  model_weights_path: byol_kitti_deeplabv3_mobilenet_pretrained.pth  # Path to model weights (relative to weights folder). If null, no weights are loaded
  hyperparameters:  # Hyperparameters for training
    epochs: 120  # Number of training epochs
    num_workers: 4  # Number of workers for data loading
    batch_size: 8  # Training batch size
    save_freq: 10  # Save model every save_freq epochs. If 0, only the best model is saved
    ema_decay: null  # Exponential moving average decay

test:
  test_dataset: linear_eval_kitti  # Dataset to use for testing
  model_weights_path: byol_eval_kitti_mobilenet_18l.pth  # Path to model weights (relative to weights folder). If null, config name is used
  loss: kitti_cross_entropy  # Loss function
  metrics: [kitti_jaccard_macro, kitti_jaccard_micro, kitti_dice]  # Metrics to evaluate
  hyperparameters:  # Hyperparameters for testing
    num_workers: 4  # Number of workers for data loading
    batch_size: 16  # Test batch size
