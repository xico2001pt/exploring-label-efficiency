name: simclr_cifar10_wideresnet28_2_1000l  # Name of experiment (used for log folder and model naming). If null, the name is the current date and time

model: cifar10_wideresnet28_2  # Name of model

selfsl_train:
  train_dataset: semi_supervised_cifar10_1000l  # Dataset to use for training
  model_weights_name: simclr_cifar10_wideresnet28_2_1000l_pretrained  # Filename to save model weights (relative to weights folder).
  optimizer: simclr_cifar10_adam  # Optimizer
  method: simclr_cifar10  # Semi-supervised method
  metrics: []  # Metrics to evaluate
  scheduler: simclr_cosine_lr  # Learning rate scheduler. Can be null
  stop_condition: null  # Condition to stop training. Can be null
  hyperparameters:  # Hyperparameters for training
    epochs: 20  # Number of training epochs
    num_workers: 4  # Number of workers for data loading
    batch_size: 128  # Training batch size
    max_num_samples: 7000  # Maximum number of samples to use for training. If -1, all samples are used
    save_freq: 30  # Save model every save_freq epochs. If 0, only the best model is saved
    ema_decay: 0.0  # Exponential moving average decay

test:
  test_dataset: cifar10  # Dataset to use for testing
  model_weights_path: fixmatch_cifar10_wideresnet28_2_1000l.pth  # Path to model weights (relative to weights folder). If null, config name is used
  loss: cross_entropy  # Loss function
  metrics: [cifar10_top1_accuracy, cifar10_top5_accuracy]  # Metrics to evaluate
  hyperparameters:  # Hyperparameters for testing
    num_workers: 4  # Number of workers for data loading
    batch_size: 128  # Test batch size
